#!/usr/bin/env python3
"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                                                                                                â•‘
â•‘   ğŸŒŸ GLOBALS.PY v5.1 - MASTER GLOBAL STATE WITH PQ-CRYPTOGRAPHY AS SOURCE OF TRUTH ğŸŒŸ        â•‘
â•‘                                                                                                â•‘
â•‘  Single source of truth for entire QTCL application with comprehensive PQ integration        â•‘
â•‘  All quantum, blockchain, database, defi, oracle, ledger, auth, and PQC state here          â•‘
â•‘  5-level hierarchical logic: Root â†’ Logic â†’ SubLogic â†’ SubÂ²Logic â†’ SubÂ³Logic â†’ Subâ´Logic   â•‘
â•‘  Thread-safe, lazy-initialized, fully instrumented, quantum-coherent & monitorable          â•‘
â•‘  PQCSystem as cryptographic foundation for all block creation and transaction signing       â•‘
â•‘                                                                                                â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
"""

import threading,logging,time,json,uuid,secrets,hashlib,queue,traceback,os
from typing import Optional,Dict,Any,List,Callable,Set,Tuple
from dataclasses import dataclass,field,asdict
from enum import Enum
from collections import defaultdict,deque
from datetime import datetime,timedelta,timezone
from functools import wraps,lru_cache
from contextlib import contextmanager
from decimal import Decimal

logger=logging.getLogger(__name__)

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ENUMS & CONSTANTS (LEVEL 0)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class SystemHealth(Enum):
    HEALTHY = "healthy"
    DEGRADED = "degraded"
    CRITICAL = "critical"
    OFFLINE = "offline"

class InitStatus(Enum):
    NOT_STARTED = "not_started"
    INITIALIZING = "initializing"
    INITIALIZED = "initialized"
    FAILED = "failed"

class LogicLevel(Enum):
    """Hierarchical logic levels"""
    LEVEL_0_ROOT = "root"
    LEVEL_1_LOGIC = "logic"
    LEVEL_2_SUBLOGIC = "sublogic"
    LEVEL_3_SUB2 = "sub2logic"
    LEVEL_4_SUB3 = "sub3logic"
    LEVEL_5_SUB4 = "sub4logic"

class ComponentType(Enum):
    """All component types in system"""
    QUANTUM = "quantum"
    BLOCKCHAIN = "blockchain"
    DATABASE = "database"
    AUTH = "authentication"
    DEFI = "defi"
    ORACLE = "oracle"
    LEDGER = "ledger"
    ADMIN = "admin"
    CORE = "core"
    TERMINAL = "terminal"

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# HIERARCHICAL LOGIC STRUCTURES (LEVELS 1-3)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

@dataclass
class FunctionSignature:
    """Maps a function at any level"""
    name: str
    module: str
    component: ComponentType
    level: LogicLevel
    params: List[str] = field(default_factory=list)
    returns: str = "Any"
    description: str = ""
    dependencies: List[str] = field(default_factory=list)
    is_async: bool = False
    cached: bool = False
    thread_safe: bool = True
    timestamp: datetime = field(default_factory=datetime.utcnow)

@dataclass
class LogicBlock:
    """Single logic block at any level - hierarchical container"""
    id: str
    level: LogicLevel
    component: ComponentType
    functions: Dict[str, FunctionSignature] = field(default_factory=dict)
    state: Dict[str, Any] = field(default_factory=dict)
    children: List['LogicBlock'] = field(default_factory=list)
    parent: Optional['LogicBlock'] = None
    cache: Dict[str, Any] = field(default_factory=dict)
    metrics: Dict[str, int] = field(default_factory=lambda: defaultdict(int))
    
    def add_function(self, func: FunctionSignature):
        """Register function in this logic block"""
        self.functions[func.name] = func
    
    def add_child(self, child: 'LogicBlock'):
        """Add sub-logic block"""
        child.parent = self
        self.children.append(child)
    
    def execute_cached(self, func_name: str, *args, **kwargs) -> Any:
        """Execute with caching if enabled"""
        key = f"{func_name}:{str(args)}{str(kwargs)}"
        if key in self.cache:
            return self.cache[key]
        return None

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ORIGINAL QUANTUM SUBSYSTEMS (PRESERVED)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

@dataclass
class QuantumSubsystems:
    """Quantum systems state"""
    heartbeat: Optional[Any] = None
    lattice: Optional[Any] = None
    neural_network: Optional[Any] = None
    w_state_manager: Optional[Any] = None
    noise_bath: Optional[Any] = None
    entropy_ensemble: Optional[Any] = None
    quantum_coordinator: Optional[Any] = None
    
    def all_initialized(self) -> bool:
        """Check if all quantum systems are initialized"""
        return all([
            self.heartbeat is not None,
            self.lattice is not None,
            self.neural_network is not None,
            self.w_state_manager is not None,
            self.noise_bath is not None
        ])
    
    def get_health(self) -> Dict[str, Any]:
        """Get health of all quantum systems"""
        return {
            'heartbeat_running': self.heartbeat.running if self.heartbeat else False,
            'heartbeat_pulse_count': self.heartbeat.pulse_count if self.heartbeat else 0,
            'heartbeat_listeners': len(self.heartbeat.listeners) if self.heartbeat else 0,
            'heartbeat_errors': self.heartbeat.error_count if self.heartbeat else 0,
            'lattice_ready': self.lattice is not None,
            'neural_network_ready': self.neural_network is not None,
            'w_state_ready': self.w_state_manager is not None,
            'noise_bath_ready': self.noise_bath is not None,
        }

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# BLOCKCHAIN STATE (NEW - DEEP INTEGRATION)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

@dataclass
class BlockchainState:
    """Blockchain systems state"""
    chain: List[Dict[str, Any]] = field(default_factory=list)
    pending_transactions: List[Dict[str, Any]] = field(default_factory=list)
    mempool_size: int = 0
    total_transactions: int = 0
    total_blocks: int = 0
    chain_height: int = 0
    last_block_time: Optional[datetime] = None
    consensus_mechanism: str = "QTCL_COHERENCE"
    
    # â˜… CRITICAL FIX: Add missing consensus & difficulty attributes
    consensus_state: str = "active"
    network_hashrate: float = 0.0
    difficulty: float = 1.0
    total_difficulty: float = 1.0
    quantum_entropy_avg: float = 0.5
    temporal_coherence: float = 0.9
    finalized_blocks: int = 0
    active_validators: int = 0
    fork_depth: int = 0
    
    # â˜… PQ cryptography metrics
    pq_signatures_verified: int = 0
    pq_keys_active: int = 0
    last_pq_verified_block: int = 0
    
    def add_transaction(self, tx: Dict[str, Any]):
        """Add pending transaction"""
        self.pending_transactions.append(tx)
        self.mempool_size = len(self.pending_transactions)
        self.total_transactions += 1
    
    def add_block(self, block: Dict[str, Any]):
        """Add block to chain"""
        self.chain.append(block)
        self.chain_height = len(self.chain)
        self.total_blocks += 1
        self.last_block_time = datetime.utcnow()
        
        # Update metrics from block if available
        if 'consensus_state' in block:
            self.consensus_state = block['consensus_state']
        if 'difficulty' in block:
            self.difficulty = float(block['difficulty'])
        if 'entropy_score' in block:
            self.quantum_entropy_avg = (self.quantum_entropy_avg + float(block['entropy_score'])) / 2
        if 'pq_signature' in block and block['pq_signature']:
            self.pq_signatures_verified += 1
            self.last_pq_verified_block = len(self.chain) - 1

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# DEFI STATE (NEW - DEEP INTEGRATION)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

@dataclass
class DeFiState:
    """DeFi systems state"""
    pools: List[Dict[str, Any]] = field(default_factory=list)
    swaps: List[Dict[str, Any]] = field(default_factory=list)
    total_liquidity: Decimal = field(default_factory=lambda: Decimal('0'))
    total_volume: Decimal = field(default_factory=lambda: Decimal('0'))
    active_pools: int = 0
    price_feed_connected: bool = False
    
    def create_pool(self, pool: Dict[str, Any]):
        """Create liquidity pool"""
        self.pools.append(pool)
        self.active_pools = len(self.pools)

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ORACLE STATE (NEW - DEEP INTEGRATION)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

@dataclass
class OracleState:
    """Oracle systems state"""
    prices: Dict[str, Decimal] = field(default_factory=dict)
    price_sources: Dict[str, List[str]] = field(default_factory=dict)
    last_update: Optional[datetime] = None
    data_points: int = 0
    aggregation_accuracy: float = 0.0
    
    def update_price(self, token: str, price: Decimal, sources: List[str]):
        """Update price data"""
        self.prices[token] = price
        self.price_sources[token] = sources
        self.last_update = datetime.utcnow()
        self.data_points += 1

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# LEDGER STATE (NEW - DEEP INTEGRATION)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

@dataclass
class LedgerState:
    """Ledger/audit trail state"""
    entries: List[Dict[str, Any]] = field(default_factory=list)
    audit_log: deque = field(default_factory=lambda: deque(maxlen=10000))
    total_entries: int = 0
    last_entry_time: Optional[datetime] = None
    
    def add_entry(self, entry: Dict[str, Any]):
        """Add ledger entry"""
        self.entries.append(entry)
        self.audit_log.append({'entry': entry, 'time': datetime.utcnow()})
        self.total_entries += 1
        self.last_entry_time = datetime.utcnow()

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# DATABASE STATE (ORIGINAL)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# POST-QUANTUM CRYPTOGRAPHY STATE (PQC - CORE CRYPTOGRAPHIC FOUNDATION)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

@dataclass
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# DATABASE STATE (ORIGINAL)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

@dataclass
class DatabaseState:
    """Database connection & state"""
    pool: Optional[Any] = None
    connection_count: int = 0
    failed_connections: int = 0
    last_error: Optional[str] = None
    last_error_time: Optional[datetime] = None
    healthy: bool = False
    query_count: int = 0
    
    def mark_connection(self, success: bool = True):
        if success:
            self.connection_count += 1
            self.healthy = True
        else:
            self.failed_connections += 1
            self.last_error_time = datetime.utcnow()

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# POST-QUANTUM CRYPTOGRAPHY STATE (PQC â€” LEVEL 2 DEEP INTEGRATION)
# Tracks every aspect of the Hyperbolic PQC system at runtime.
# Sub-logic: HyperbolicPQCSystem â†’ KeyVaultManager â†’ RevocationEngine â†’ ZK nullifier store
# SubÂ²-logic: QuantumEntropyHarvester rate-limit telemetry per source
# SubÂ³-logic: Per-user key tree metrics (depth, rotation count, share count)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

@dataclass
class PQCState:
    """
    Live telemetry for the Hyperbolic Post-Quantum Cryptography subsystem.

    Architectural hierarchy:
      Level 0 â€” HyperbolicMath          : {8,3}-tessellation primitive ops
      Level 1 â€” HLWESampler             : keypair generation on PoincarÃ© disk
      Level 2 â€” HyperKEM / HyperSign    : IND-CCA2 encapsulation + EUF-CMA signing
      Level 3 â€” HyperbolicKeyGenerator  : HD key tree (master â†’ subkeys)
      Level 4 â€” HyperbolicSecretSharing, HyperZKProver : threshold sharing + ZK
      Level 5 â€” KeyVaultManager         : AES-256-GCM encrypted DB vault + revocation
    """
    # â”€â”€ System handle â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    system: Optional[Any] = None          # HyperbolicPQCSystem singleton
    initialized: bool = False
    init_error: Optional[str] = None
    params_name: str = 'HLWE-256'         # HLWE-128 / HLWE-192 / HLWE-256

    # â”€â”€ Capability flags (set during init from system.status()) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    mpmath_available: bool = False        # 150-decimal precision arithmetic
    liboqs_available: bool = False        # CRYSTALS-Kyber + Dilithium hybrid
    cryptography_available: bool = False  # AES-256-GCM vault encryption
    kyber_hybrid: bool = False            # HLWE + Kyber dual-encap
    dilithium_hybrid: bool = False        # HLWE + Dilithium dual-sign

    # â”€â”€ Key lifecycle counters â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    keys_generated: int = 0              # total master keys created
    keys_active: int = 0                 # live, non-expired, non-revoked
    keys_rotated: int = 0               # successful rotations
    keys_revoked: int = 0               # total revocations (including cascades)
    subkeys_derived: int = 0            # signing / encryption / session subkeys
    shares_issued: int = 0              # secret-sharing shares created

    # â”€â”€ Cryptographic operation counters â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    signatures_produced: int = 0
    signatures_verified: int = 0
    encapsulations: int = 0
    decapsulations: int = 0
    zk_proofs_produced: int = 0
    zk_proofs_verified: int = 0
    zk_replays_blocked: int = 0

    # â”€â”€ QRNG entropy telemetry (subÂ²-logic) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    entropy_harvests: int = 0
    entropy_bytes_generated: int = 0
    anu_source_hits: int = 0
    random_org_hits: int = 0
    lfdr_hits: int = 0
    local_csprng_hits: int = 0           # always incremented (always used)

    # â”€â”€ Vault metrics â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    vault_stores: int = 0
    vault_retrievals: int = 0
    vault_schema_ready: bool = False

    # â”€â”€ ZK nullifier store (in-memory replay protection) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    zk_nullifiers: Set[str] = field(default_factory=set)

    # â”€â”€ Per-user key tree registry (subÂ³-logic) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # user_id â†’ { master_key_id, signing_key_id, enc_key_id, rotation_count, ... }
    user_key_registry: Dict[str, Dict[str, Any]] = field(default_factory=dict)

    # â”€â”€ Tessellation metrics â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    tessellation_depth: int = 5          # {8,3} subdivision depth
    total_pseudoqubits: int = 106496     # 8 Ã— 4^5 Ã— 13 = 106,496 lattice positions
    pseudoqubits_assigned: int = 0       # live count from DB

    # â”€â”€ Recent operation log (ring buffer) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    recent_ops: deque = field(default_factory=lambda: deque(maxlen=200))

    def record_op(self, op: str, user_id: str = '', key_id: str = '',
                  success: bool = True, detail: str = ''):
        """Append an operation to the recent-ops ring buffer."""
        self.recent_ops.append({
            'op': op, 'user_id': user_id,
            'key_id': key_id[:8] + 'â€¦' if len(key_id) > 8 else key_id,
            'success': success, 'detail': detail,
            'ts': datetime.now(timezone.utc).isoformat(),
        })

    def register_user_keys(self, user_id: str, bundle: Dict[str, Any]):
        """Persist key IDs for a user in the in-memory registry."""
        self.user_key_registry[user_id] = {
            'master_key_id':    bundle.get('master_key', {}).get('key_id', ''),
            'signing_key_id':   bundle.get('signing_key', {}).get('key_id', ''),
            'enc_key_id':       bundle.get('encryption_key', {}).get('key_id', ''),
            'fingerprint':      bundle.get('fingerprint', ''),
            'pseudoqubit_id':   bundle.get('pseudoqubit_id', 0),
            'params':           bundle.get('params', self.params_name),
            'issued_at':        datetime.now(timezone.utc).isoformat(),
            'rotation_count':   self.user_key_registry.get(user_id, {}).get('rotation_count', 0),
        }

    def get_summary(self) -> Dict[str, Any]:
        """Return a JSON-serialisable status snapshot for health/status endpoints."""
        return {
            'initialized':          self.initialized,
            'params':               self.params_name,
            'hard_problem':         'HLWE â€” PSL(2,â„) / {8,3} tessellation',
            'security_bits':        int(self.params_name.split('-')[-1]) if '-' in self.params_name else 256,
            'mpmath':               self.mpmath_available,
            'liboqs_hybrid':        self.liboqs_available,
            'kyber_hybrid':         self.kyber_hybrid,
            'dilithium_hybrid':     self.dilithium_hybrid,
            'vault_schema_ready':   self.vault_schema_ready,
            'keys': {
                'generated':        self.keys_generated,
                'active':           self.keys_active,
                'rotated':          self.keys_rotated,
                'revoked':          self.keys_revoked,
                'subkeys_derived':  self.subkeys_derived,
            },
            'operations': {
                'signatures_produced':  self.signatures_produced,
                'signatures_verified':  self.signatures_verified,
                'encapsulations':       self.encapsulations,
                'decapsulations':       self.decapsulations,
                'zk_proofs':            self.zk_proofs_produced,
                'zk_replays_blocked':   self.zk_replays_blocked,
            },
            'entropy': {
                'total_harvests':   self.entropy_harvests,
                'total_bytes':      self.entropy_bytes_generated,
                'sources': {
                    'anu_qrng':     self.anu_source_hits,
                    'random_org':   self.random_org_hits,
                    'lfdr_qrng':    self.lfdr_hits,
                    'local_csprng': self.local_csprng_hits,
                }
            },
            'tessellation': {
                'scheme':               '{8,3} hyperbolic',
                'depth':                self.tessellation_depth,
                'total_positions':      self.total_pseudoqubits,
                'assigned':             self.pseudoqubits_assigned,
            },
            'users_with_keys':      len(self.user_key_registry),
            'error':                self.init_error,
        }

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# AUTHENTICATION STATE (ORIGINAL + EXPANDED)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

@dataclass
class AuthenticationState:
    """Authentication systems state"""
    jwt_manager: Optional[Any] = None
    session_store: Dict[str, Dict[str, Any]] = field(default_factory=dict)
    active_sessions: int = 0
    users: Dict[str, Dict[str, Any]] = field(default_factory=dict)
    failed_attempts: Dict[str, List[datetime]] = field(default_factory=lambda: defaultdict(list))
    mfa_enabled: bool = False
    
    def get_failed_attempts(self, user_id: str, window_minutes: int = 15) -> int:
        """Get failed login attempts in time window"""
        cutoff = datetime.utcnow() - timedelta(minutes=window_minutes)
        self.failed_attempts[user_id] = [
            t for t in self.failed_attempts[user_id] if t > cutoff
        ]
        return len(self.failed_attempts[user_id])

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# TERMINAL STATE (ORIGINAL)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

@dataclass
class TerminalState:
    """Command execution engine state"""
    engine: Optional[Any] = None
    command_registry: Dict[str, Callable] = field(default_factory=dict)
    executed_commands: int = 0
    failed_commands: int = 0
    last_command: Optional[str] = None
    last_command_time: Optional[datetime] = None

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# METRICS (ORIGINAL + EXPANDED)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

@dataclass
class BlockCommandMetrics:
    """Block command metrics tracking"""
    all_blocks_queries: int = 0
    list_blocks_queries: int = 0
    history_queries: int = 0
    details_queries: int = 0
    stats_queries: int = 0
    total_blocks_retrieved: int = 0
    query_times: deque = field(default_factory=lambda: deque(maxlen=1000))
    cache_hits: int = 0
    cache_misses: int = 0
    
    def record_all_blocks_query(self, duration_ms: float, count: int):
        self.all_blocks_queries += 1
        self.total_blocks_retrieved += count
        self.query_times.append({'type': 'all', 'duration_ms': duration_ms, 'timestamp': datetime.utcnow()})
    
    def record_list_blocks_query(self, duration_ms: float, count: int):
        self.list_blocks_queries += 1
        self.total_blocks_retrieved += count
        self.query_times.append({'type': 'list', 'duration_ms': duration_ms, 'timestamp': datetime.utcnow()})
    
    def record_history_query(self, duration_ms: float):
        self.history_queries += 1
        self.query_times.append({'type': 'history', 'duration_ms': duration_ms, 'timestamp': datetime.utcnow()})
    
    def record_details_query(self, duration_ms: float):
        self.details_queries += 1
        self.query_times.append({'type': 'details', 'duration_ms': duration_ms, 'timestamp': datetime.utcnow()})
    
    def record_stats_query(self, duration_ms: float):
        self.stats_queries += 1
        self.query_times.append({'type': 'stats', 'duration_ms': duration_ms, 'timestamp': datetime.utcnow()})
    
    def record_cache_hit(self):
        self.cache_hits += 1
    
    def record_cache_miss(self):
        self.cache_misses += 1

@dataclass
class ApplicationMetrics:
    """Application-wide metrics"""
    http_requests: int = 0
    http_errors: int = 0
    commands_executed: int = 0
    quantum_pulses: int = 0
    transactions_processed: int = 0
    blocks_created: int = 0
    swaps_executed: int = 0
    price_updates: int = 0
    ledger_entries: int = 0
    api_calls: Dict[str, int] = field(default_factory=lambda: defaultdict(int))
    request_times: deque = field(default_factory=lambda: deque(maxlen=1000))
    error_log: deque = field(default_factory=lambda: deque(maxlen=100))
    
    def add_request(self, duration_ms: float):
        """Track request timing"""
        self.http_requests += 1
        self.request_times.append({'time': datetime.utcnow(), 'duration_ms': duration_ms})
    
    def add_error(self, error: str):
        """Log error"""
        self.http_errors += 1
        self.error_log.append({'time': datetime.utcnow(), 'error': error})
    
    def get_stats(self) -> Dict[str, Any]:
        """Get metrics snapshot"""
        avg_request_time = 0
        if self.request_times:
            avg_request_time = sum(r['duration_ms'] for r in self.request_times) / len(self.request_times)
        
        return {
            'http_requests': self.http_requests,
            'http_errors': self.http_errors,
            'error_rate': self.http_errors / max(self.http_requests, 1),
            'quantum_pulses': self.quantum_pulses,
            'transactions': self.transactions_processed,
            'blocks': self.blocks_created,
            'swaps': self.swaps_executed,
            'price_updates': self.price_updates,
            'ledger_entries': self.ledger_entries,
            'avg_request_time_ms': avg_request_time,
            'unique_endpoints': len(self.api_calls),
        }

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# RATE LIMITING (ORIGINAL)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

@dataclass
class RateLimiting:
    """Rate limiting state"""
    store: Dict[str, deque] = field(default_factory=lambda: defaultdict(lambda: deque(maxlen=100)))
    limits: Dict[str, int] = field(default_factory=lambda: {'default': 100})
    
    def check_limit(self, key: str, limit: Optional[int] = None) -> bool:
        """Check if request is within rate limit"""
        if limit is None:
            limit = self.limits.get(key, self.limits['default'])
        
        now = time.time()
        cutoff = now - 60
        
        self.store[key] = deque(
            [t for t in self.store[key] if t > cutoff],
            maxlen=100
        )
        
        if len(self.store[key]) >= limit:
            return False
        
        self.store[key].append(now)
        return True

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# MAIN GLOBAL STATE (MASSIVELY EXPANDED)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

@dataclass
class GlobalState:
    """
    UNIFIED APPLICATION STATE - SINGLE SOURCE OF TRUTH (EXPANDED)
    
    This is the heart of QTCL v5.0. Contains:
    - All component states (Quantum, Blockchain, DeFi, Oracle, Ledger, Auth, DB, Terminal)
    - Hierarchical logic blocks (5 levels deep, 10 major components)
    - Function registry and discovery system
    - Cross-module integration hooks
    - Quantum coherence threading
    - Global metrics and monitoring
    """
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # INITIALIZATION & STATUS
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    lock: threading.RLock = field(default_factory=threading.RLock)
    init_status: InitStatus = InitStatus.NOT_STARTED
    init_start_time: Optional[datetime] = None
    init_errors: List[str] = field(default_factory=list)
    initialized: bool = False
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # SYSTEM COMPONENTS (ORIGINAL)
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    quantum: QuantumSubsystems = field(default_factory=QuantumSubsystems)
    database: DatabaseState = field(default_factory=DatabaseState)
    auth: AuthenticationState = field(default_factory=AuthenticationState)
    terminal: TerminalState = field(default_factory=TerminalState)
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # NEW COMPONENT STATES (DEEP INTEGRATION)
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    blockchain: BlockchainState = field(default_factory=BlockchainState)
    defi: DeFiState = field(default_factory=DeFiState)
    oracle: OracleState = field(default_factory=OracleState)
    ledger: LedgerState = field(default_factory=LedgerState)
    pqc: PQCState = field(default_factory=PQCState)   # Hyperbolic PQC subsystem
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # APPLICATION STATE
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    metrics: ApplicationMetrics = field(default_factory=ApplicationMetrics)
    block_command_metrics: BlockCommandMetrics = field(default_factory=BlockCommandMetrics)
    rate_limiting: RateLimiting = field(default_factory=RateLimiting)
    config: Dict[str, Any] = field(default_factory=dict)
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # SESSION MANAGEMENT
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    sessions: Dict[str, Dict[str, Any]] = field(default_factory=dict)
    request_context: Dict[str, Any] = field(default_factory=dict)
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # HIERARCHICAL LOGIC BLOCKS (LEVEL 1) - NEW
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    quantum_logic: Optional[LogicBlock] = None
    blockchain_logic: Optional[LogicBlock] = None
    database_logic: Optional[LogicBlock] = None
    auth_logic: Optional[LogicBlock] = None
    defi_logic: Optional[LogicBlock] = None
    oracle_logic: Optional[LogicBlock] = None
    ledger_logic: Optional[LogicBlock] = None
    admin_logic: Optional[LogicBlock] = None
    core_logic: Optional[LogicBlock] = None
    terminal_logic: Optional[LogicBlock] = None
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # FUNCTION REGISTRY & DISCOVERY - NEW
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    all_functions: Dict[str, FunctionSignature] = field(default_factory=dict)
    function_dependencies: Dict[str, Set[str]] = field(default_factory=lambda: defaultdict(set))
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # SYSTEM HEALTH & MONITORING
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    startup_time: Optional[datetime] = None
    last_health_check: Optional[datetime] = None
    health: SystemHealth = SystemHealth.OFFLINE
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # METHODS
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    def get_system_health(self) -> Dict[str, Any]:
        """Comprehensive system health check"""
        with self.lock:
            quantum_health = self.quantum.get_health()
            
            is_healthy = (
                quantum_health.get('heartbeat_running', False) and
                self.database.healthy and
                not self.init_errors
            )
            
            health_status = SystemHealth.HEALTHY if is_healthy else SystemHealth.DEGRADED
            if not quantum_health.get('heartbeat_running', False):
                health_status = SystemHealth.OFFLINE
            
            self.health = health_status
            self.last_health_check = datetime.utcnow()
            
            return {
                'status': health_status.value,
                'timestamp': datetime.utcnow().isoformat(),
                'uptime_seconds': (datetime.utcnow() - self.startup_time).total_seconds() if self.startup_time else 0,
                'quantum': quantum_health,
                'blockchain': {
                    'chain_height': self.blockchain.chain_height,
                    'pending_tx': self.blockchain.mempool_size,
                    'total_transactions': self.blockchain.total_transactions,
                },
                'defi': {
                    'active_pools': self.defi.active_pools,
                    'total_volume': str(self.defi.total_volume),
                },
                'oracle': {
                    'price_points': self.oracle.data_points,
                    'last_update': self.oracle.last_update.isoformat() if self.oracle.last_update else None,
                },
                'ledger': {
                    'total_entries': self.ledger.total_entries,
                },
                'database': {
                    'healthy': self.database.healthy,
                    'connection_count': self.database.connection_count,
                },
                'pqc': self.pqc.get_summary(),
                'metrics': self.metrics.get_stats(),
                'init_status': self.init_status.value,
                'functions_registered': len(self.all_functions),
            }
    
    def snapshot(self) -> Dict[str, Any]:
        """Get complete state snapshot"""
        with self.lock:
            return {
                'initialized': self.initialized,
                'health': self.health.value,
                'blockchain': {
                    'chain_length': len(self.blockchain.chain),
                    'pending_tx': len(self.blockchain.pending_transactions),
                },
                'defi': {
                    'pools': len(self.defi.pools),
                    'total_liquidity': str(self.defi.total_liquidity),
                },
                'oracle': {
                    'prices': {k: str(v) for k, v in self.oracle.prices.items()},
                },
                'ledger': {
                    'entries': len(self.ledger.entries),
                },
                'auth': {
                    'users': len(self.auth.users),
                    'sessions': len(self.sessions),
                },
                'database': {
                    'connections': self.database.connection_count,
                    'healthy': self.database.healthy,
                },
                'metrics': self.metrics.get_stats(),
                'timestamp': datetime.utcnow().isoformat(),
                'functions_registered': len(self.all_functions),
            }

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# GLOBAL SINGLETON INSTANCE
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

_GLOBAL_STATE: Optional[GlobalState] = None
_GLOBAL_LOCK = threading.RLock()

def get_globals() -> GlobalState:
    """Get or create global state singleton"""
    global _GLOBAL_STATE
    if _GLOBAL_STATE is None:
        with _GLOBAL_LOCK:
            if _GLOBAL_STATE is None:
                _GLOBAL_STATE = GlobalState()
                _GLOBAL_STATE.startup_time = datetime.utcnow()
    return _GLOBAL_STATE

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# INITIALIZATION (MASSIVELY EXPANDED)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def initialize_globals() -> bool:
    """Initialize all global state - calls all init functions"""
    logger.info("â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—")
    logger.info("â•‘         INITIALIZING GLOBAL ARCHITECTURE MASTER v5.0              â•‘")
    logger.info("â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
    
    globals_inst = get_globals()
    
    with globals_inst.lock:
        globals_inst.init_status = InitStatus.INITIALIZING
        globals_inst.init_start_time = datetime.utcnow()
    
    try:
        # Initialize hierarchical logic
        _init_logic_hierarchy(globals_inst)
        
        # Initialize quantum systems
        _init_quantum(globals_inst)
        
        # Initialize database
        _init_database(globals_inst)
        
        # Initialize authentication
        _init_authentication(globals_inst)
        
        # Initialize terminal
        _init_terminal(globals_inst)
        
        # Build function registry
        _build_function_registry(globals_inst)
        
        # Establish integrations
        _establish_integrations(globals_inst)
        
        # Initialize Post-Quantum Cryptography subsystem (non-fatal â€” system runs without it)
        _init_pqc(globals_inst)
        
        # Wire quantum lattice subsystems (non-fatal)
        try:
            wire_heartbeat_to_globals()
        except Exception as _whe:
            logger.warning(f"[Globals] Lattice wiring deferred: {_whe}")
        
        with globals_inst.lock:
            globals_inst.initialized = True
            globals_inst.init_status = InitStatus.INITIALIZED
            globals_inst.health = SystemHealth.HEALTHY
        
        logger.info("âœ… Global Architecture Master initialized successfully")
        logger.info(f"âœ… Functions registered: {len(globals_inst.all_functions)}")
        pqc_ok = globals_inst.pqc.initialized
        logger.info(f"{'âœ…' if pqc_ok else 'âš ï¸ '} Post-Quantum Cryptography: {'HLWE-'+globals_inst.pqc.params_name if pqc_ok else 'unavailable (non-fatal)'}")
        return True
    
    except Exception as e:
        logger.error(f"âŒ Failed to initialize global state: {e}")
        with globals_inst.lock:
            globals_inst.init_status = InitStatus.FAILED
            globals_inst.init_errors.append(str(e))
            globals_inst.health = SystemHealth.OFFLINE
        return False

class SystemHeartbeat:
    """System-wide heartbeat for keeping server alive and tracking metrics"""
    
    def __init__(self, interval: float = 30.0):
        """
        Initialize heartbeat
        
        Args:
            interval: Heartbeat interval in seconds (default 30s)
        """
        self.interval = interval
        self.running = False
        self.pulse_count = 0
        self.listeners = []
        self.error_count = 0
        self.last_beat_time = None
        self.lock = threading.RLock()
        self.thread = None
        self.metrics = {
            'cpu_usage': 0.0,
            'memory_usage': 0.0,
            'request_count': 0,
            'error_count': 0,
            'avg_response_time': 0.0,
            'quantum_pulses': 0,
            'timestamp': datetime.utcnow().isoformat(),
        }
    
    def start(self):
        """Start the heartbeat thread"""
        with self.lock:
            if self.running:
                return
            self.running = True
        
        self.thread = threading.Thread(target=self._beat_loop, daemon=True)
        self.thread.name = "SystemHeartbeat"
        self.thread.start()
        logger.info("[Heartbeat] âœ“ Heartbeat started (30s interval)")
    
    def stop(self):
        """Stop the heartbeat"""
        with self.lock:
            self.running = False
        
        if self.thread:
            self.thread.join(timeout=5)
        logger.info("[Heartbeat] âœ“ Heartbeat stopped")
    
    def add_listener(self, callback: Callable):
        """Register a callback to be called on each heartbeat"""
        with self.lock:
            if callback not in self.listeners:
                self.listeners.append(callback)
    
    def _beat_loop(self):
        """Main heartbeat loop - runs every 30 seconds"""
        logger.info("[Heartbeat] Beat loop started")
        while self.running:
            try:
                time.sleep(self.interval)
                if not self.running:
                    break
                
                self.beat()
            except Exception as e:
                logger.error(f"[Heartbeat] Error in beat loop: {e}")
                self.error_count += 1
                time.sleep(5)
    
    def beat(self):
        """Execute a heartbeat pulse"""
        with self.lock:
            try:
                self.pulse_count += 1
                self.last_beat_time = datetime.utcnow()
                
                # Update metrics
                gs = get_globals()
                self.metrics['timestamp'] = datetime.utcnow().isoformat()
                self.metrics['request_count'] = gs.metrics.http_requests
                self.metrics['error_count'] = gs.metrics.http_errors
                self.metrics['quantum_pulses'] = gs.metrics.quantum_pulses
                
                # Calculate average response time
                if gs.metrics.request_times:
                    avg_time = sum(r['duration_ms'] for r in gs.metrics.request_times) / len(gs.metrics.request_times)
                    self.metrics['avg_response_time'] = round(avg_time, 2)
                
                logger.debug(f"[Heartbeat] Pulse #{self.pulse_count} - {self.pulse_count * self.interval}s elapsed")
                
                # Call listeners
                for listener in self.listeners:
                    try:
                        listener(self.last_beat_time)
                    except Exception as e:
                        logger.error(f"[Heartbeat] Listener error: {e}")
                        self.error_count += 1
                
                # Post to API heartbeat endpoint to keep server alive
                self._post_heartbeat_to_api()
            
            except Exception as e:
                logger.error(f"[Heartbeat] Beat execution error: {e}")
                self.error_count += 1
    
    def _post_heartbeat_to_api(self):
        """POST heartbeat to /api/heartbeat endpoint to keep server alive"""
        try:
            payload = {
                'pulse': self.pulse_count,
                'timestamp': datetime.utcnow().isoformat(),
                'metrics': self.metrics
            }
            
            # Make async call to avoid blocking
            def _async_post():
                try:
                    import requests
                    requests.post(
                        'http://localhost:5000/api/heartbeat',
                        json=payload,
                        timeout=2
                    )
                except Exception:
                    pass
            
            # Post asynchronously
            post_thread = threading.Thread(target=_async_post, daemon=True)
            post_thread.start()
        
        except Exception:
            pass
    
    def get_metrics(self) -> Dict[str, Any]:
        """Get current metrics"""
        with self.lock:
            return dict(self.metrics)


def _init_quantum(globals_inst: GlobalState):
    """Initialize quantum systems including heartbeat"""
    logger.info("[Init] Initializing quantum systems...")
    try:
        # Try to import quantum components
        try:
            from quantum_lattice_control_live_complete import QuantumLatticeControlLiveV5
            lattice = QuantumLatticeControlLiveV5()
            with globals_inst.lock:
                globals_inst.quantum.lattice = lattice
            logger.info("[Init] âœ“ Quantum Lattice initialized")
        except Exception as e:
            logger.warning(f"[Init] Quantum Lattice not available: {e}")
        
        # Initialize heartbeat system - CRITICAL
        heartbeat = SystemHeartbeat(interval=30.0)
        with globals_inst.lock:
            globals_inst.quantum.heartbeat = heartbeat
        
        # Start heartbeat in background
        heartbeat.start()
        logger.info("[Init] âœ“ System Heartbeat initialized (30s interval, auto-posting to /api/heartbeat)")
        
        return True
    except Exception as e:
        logger.error(f"[Init] Quantum initialization failed: {e}")
        with globals_inst.lock:
            globals_inst.init_errors.append(f"Quantum init: {e}")
        return False


def _init_logic_hierarchy(globals_inst: GlobalState):
    """Initialize hierarchical logic blocks (LEVEL 1)"""
    logger.info("[Init] Creating logic hierarchy...")
    
    # Create root logic blocks for each component
    globals_inst.quantum_logic = LogicBlock(
        id="quantum_root",
        level=LogicLevel.LEVEL_1_LOGIC,
        component=ComponentType.QUANTUM
    )
    
    globals_inst.blockchain_logic = LogicBlock(
        id="blockchain_root",
        level=LogicLevel.LEVEL_1_LOGIC,
        component=ComponentType.BLOCKCHAIN
    )
    
    globals_inst.database_logic = LogicBlock(
        id="database_root",
        level=LogicLevel.LEVEL_1_LOGIC,
        component=ComponentType.DATABASE
    )
    
    globals_inst.auth_logic = LogicBlock(
        id="auth_root",
        level=LogicLevel.LEVEL_1_LOGIC,
        component=ComponentType.AUTH
    )
    
    globals_inst.defi_logic = LogicBlock(
        id="defi_root",
        level=LogicLevel.LEVEL_1_LOGIC,
        component=ComponentType.DEFI
    )
    
    globals_inst.oracle_logic = LogicBlock(
        id="oracle_root",
        level=LogicLevel.LEVEL_1_LOGIC,
        component=ComponentType.ORACLE
    )
    
    globals_inst.ledger_logic = LogicBlock(
        id="ledger_root",
        level=LogicLevel.LEVEL_1_LOGIC,
        component=ComponentType.LEDGER
    )
    
    globals_inst.admin_logic = LogicBlock(
        id="admin_root",
        level=LogicLevel.LEVEL_1_LOGIC,
        component=ComponentType.ADMIN
    )
    
    globals_inst.core_logic = LogicBlock(
        id="core_root",
        level=LogicLevel.LEVEL_1_LOGIC,
        component=ComponentType.CORE
    )
    
    globals_inst.terminal_logic = LogicBlock(
        id="terminal_root",
        level=LogicLevel.LEVEL_1_LOGIC,
        component=ComponentType.TERMINAL
    )
    
    logger.info("[Init] âœ… Logic hierarchy created (10 blocks)")



def _init_database(globals_inst: GlobalState):
    """Initialize database connection pool â€” with detailed logging for debugging."""
    logger.info("[Globals] Initializing database connection pool...")
    
    try:
        import db_builder_v2 as _db_mod
        logger.debug("[Globals] db_builder_v2 module loaded successfully")
        
        # Try to get the pool that was initialized during db_builder_v2 import
        pool = getattr(_db_mod, 'DB_POOL', None)
        db_manager = getattr(_db_mod, 'db_manager', None)
        init_fn = getattr(_db_mod, 'init_db', None)
        
        logger.debug(f"[Globals] DB_POOL from db_builder_v2: {pool is not None}")
        logger.debug(f"[Globals] db_manager from db_builder_v2: {db_manager is not None}")
        
        # Use whichever is available (prefer DB_POOL, fallback to db_manager)
        final_pool = pool or db_manager
        
        with globals_inst.lock:
            globals_inst.database.pool = final_pool
            globals_inst.database.healthy = final_pool is not None
        
        # If pool exists, validate it
        if final_pool is not None:
            logger.info("[Globals] âœ… Database pool obtained from db_builder_v2")
            try:
                # Try to get a connection to verify the pool works
                conn = final_pool.get_connection()
                if conn:
                    final_pool.return_connection(conn)
                    logger.info("[Globals] âœ… Database pool validation successful (connection alive)")
                    # Eagerly populate in-memory stats from live DB
                    _populate_blockchain_stats(globals_inst, final_pool)
                else:
                    logger.warning("[Globals] âš ï¸  Pool exists but get_connection() returned None")
                    with globals_inst.lock:
                        globals_inst.database.healthy = False
            except Exception as conn_err:
                logger.warning(f"[Globals] âš ï¸  Database pool exists but connection test failed: {conn_err}")
                logger.warning("[Globals] Database will be available for lazy-load on first use")
                # Don't mark as unhealthy â€” pool might recover on next request
        else:
            logger.warning("[Globals] âš ï¸  db_builder_v2.DB_POOL is None â€” database not initialized")
            logger.warning("[Globals] Database will be lazy-loaded on first use (commands will work)")
            
            # Try calling init_fn to attempt initialization
            if init_fn:
                try:
                    init_result = init_fn()
                    logger.info(f"[Globals] init_db() returned: {init_result}")
                except Exception as init_err:
                    logger.debug(f"[Globals] init_db() failed: {init_err}")
            
            with globals_inst.lock:
                globals_inst.database.healthy = False

    except ImportError as e:
        logger.error(f"[Globals] âŒ db_builder_v2 import failed: {e}")
        logger.error("[Globals] Database will NOT be available â€” check logs above")
        with globals_inst.lock:
            globals_inst.database.healthy = False
        
    except Exception as e:
        logger.error(f"[Globals] âŒ Database initialization error: {e}")
        import traceback
        logger.debug(f"[Globals] Traceback: {traceback.format_exc()}")
        with globals_inst.lock:
            globals_inst.database.healthy = False


def _populate_blockchain_stats(globals_inst: GlobalState, pool):
    """Read live DB counts into in-memory GlobalState so health/status endpoints
    show real numbers instead of zeros."""
    try:
        conn = pool.get_connection()
        cur = conn.cursor()
        
        try:
            # blocks table
            try:
                cur.execute("SELECT COUNT(*) FROM blocks")
                row = cur.fetchone()
                if row and row[0]:
                    with globals_inst.lock:
                        globals_inst.blockchain.chain_height = int(row[0])
                        globals_inst.blockchain.total_blocks = int(row[0])
                    logger.info(f"[Globals] blockchain.chain_height = {globals_inst.blockchain.chain_height}")
            except Exception as _e:
                logger.debug(f"[Globals] blocks count failed: {_e}")
            
            # transactions table
            try:
                cur.execute("SELECT COUNT(*) FROM transactions")
                row = cur.fetchone()
                if row and row[0]:
                    with globals_inst.lock:
                        globals_inst.blockchain.total_transactions = int(row[0])
            except Exception:
                pass
            
            # pending transactions
            try:
                cur.execute("SELECT COUNT(*) FROM transactions WHERE status='pending'")
                row = cur.fetchone()
                if row and row[0]:
                    with globals_inst.lock:
                        globals_inst.blockchain.mempool_size = int(row[0])
            except Exception:
                pass
            
            # ledger entries
            try:
                cur.execute("SELECT COUNT(*) FROM ledger_entries")
                row = cur.fetchone()
                if row and row[0]:
                    with globals_inst.lock:
                        globals_inst.ledger.total_entries = int(row[0])
            except Exception:
                pass
            
            # active users count
            try:
                cur.execute("SELECT COUNT(*) FROM users WHERE is_active=TRUE AND is_deleted=FALSE")
                row = cur.fetchone()
                if row and row[0]:
                    logger.info(f"[Globals] active users in DB = {row[0]}")
            except Exception:
                pass
            
            # DeFi pools
            try:
                cur.execute("SELECT COUNT(*) FROM liquidity_pools WHERE is_active=TRUE")
                row = cur.fetchone()
                if row and row[0]:
                    with globals_inst.lock:
                        globals_inst.defi.active_pools = int(row[0])
            except Exception:
                pass
            
            logger.info(f"[Globals] âœ… DB stats populated: chain={globals_inst.blockchain.chain_height} txns={globals_inst.blockchain.total_transactions}")
        finally:
            cur.close()
            pool.return_connection(conn)
    except Exception as e:
        logger.warning(f"[Globals] _populate_blockchain_stats error (non-fatal): {e}")

def _init_authentication(globals_inst: GlobalState):
    """Initialize authentication systems â€” tries JWTTokenManager then TokenManager."""
    logger.info("[Globals] Initializing authentication...")
    try:
        import auth_handlers as _ah_mod
        # Primary public name is JWTTokenManager; fall back to TokenManager
        cls = getattr(_ah_mod, 'JWTTokenManager', None) or getattr(_ah_mod, 'TokenManager', None)
        if cls is None:
            raise ImportError("Neither JWTTokenManager nor TokenManager found in auth_handlers")
        jwt_manager = cls()
        with globals_inst.lock:
            globals_inst.auth.jwt_manager = jwt_manager
        logger.info(f"[Globals] âœ… Authentication initialized via {cls.__name__}")
    except ImportError as e:
        logger.warning(f"[Globals] Auth not available: {e}")
    except Exception as e:
        logger.warning(f"[Globals] Auth init error (continuing): {e}")

def _init_terminal(globals_inst: GlobalState):
    """
    Register terminal subsystem in globals state.
    NOTE: TerminalEngine is NOT instantiated here â€” wsgi_config._boot_terminal() owns that.
    Doing it here too caused double-init crashes. globals just marks the subsystem ready.
    """
    logger.info("[Globals] Initializing terminal slot (engine boots via wsgi_config)...")
    with globals_inst.lock:
        globals_inst.terminal.command_registry = {}  # will be filled by register_all_commands()
    logger.info("[Globals] âœ… Terminal slot ready")


def _init_pqc(globals_inst: GlobalState):
    """
    Initialize the Hyperbolic Post-Quantum Cryptography subsystem.

    Sub-logic hierarchy:
      Level 1 â€” Import HyperbolicPQCSystem singleton (lazy, thread-safe)
      Level 2 â€” Call system.status() to populate capability flags in PQCState
      Level 3 â€” Ensure KeyVaultManager DB schema is created
      Level 4 â€” Seed pseudoqubit count from live DB
      Level 5 â€” Register PQC telemetry hooks on entropy harvester

    Non-fatal: if pq_key_system.py is unavailable the rest of the application
    continues normally; pqc.initialized remains False and endpoints degrade gracefully.
    """
    logger.info("[Init] Initializing Post-Quantum Cryptography subsystem (HLWE / {8,3})...")
    pqc_state = globals_inst.pqc

    try:
        from pq_key_system import get_pqc_system, HLWE_256
        pqc_sys = get_pqc_system(HLWE_256)

        # â”€â”€ Level 2: populate capability flags from live status â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        status = pqc_sys.status()
        with globals_inst.lock:
            pqc_state.system               = pqc_sys
            pqc_state.params_name          = status.get('params', 'HLWE-256')
            pqc_state.mpmath_available     = status.get('mpmath_precision', '') != 'float64'
            pqc_state.liboqs_available     = bool(status.get('liboqs', False))
            pqc_state.cryptography_available = True   # if import succeeded
            pqc_state.kyber_hybrid         = bool(status.get('kyber_hybrid', False))
            pqc_state.dilithium_hybrid     = bool(status.get('dilithium_hybrid', False))

        # â”€â”€ Level 3: vault schema â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        try:
            schema_ok = pqc_sys.vault.ensure_schema()
            with globals_inst.lock:
                pqc_state.vault_schema_ready = schema_ok
            if schema_ok:
                logger.info("[Init/PQC] âœ… Key vault schema ready (pq_key_store, pq_key_revocations, pq_zk_nullifiers)")
        except Exception as _se:
            logger.warning(f"[Init/PQC] Vault schema deferred: {_se}")

        # â”€â”€ Level 4: seed pseudoqubit count from DB â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        try:
            pool = globals_inst.database.pool
            if pool is not None:
                conn = pool.get_connection()
                try:
                    cur = conn.cursor()
                    cur.execute("SELECT COUNT(*) FROM pseudoqubits WHERE status='assigned'")
                    row = cur.fetchone()
                    if row and row[0]:
                        with globals_inst.lock:
                            pqc_state.pseudoqubits_assigned = int(row[0])
                    cur.close()
                finally:
                    pool.return_connection(conn)
        except Exception as _pe:
            logger.debug(f"[Init/PQC] Pseudoqubit count skipped: {_pe}")

        # â”€â”€ Level 5: hook entropy telemetry â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # Monkey-patch QuantumEntropyHarvester.harvest to count hits in PQCState.
        # This is safe: harvest() is pure-function, lock-free on the telemetry side.
        try:
            orig_harvest = pqc_sys.entropy.harvest.__func__ if hasattr(pqc_sys.entropy.harvest, '__func__') else None
            _pqc_state_ref = pqc_state  # closure capture

            def _instrumented_harvest(self_e, n_bytes: int = 64, require_remote: bool = False):
                result = pqc_sys.entropy.__class__.harvest(self_e, n_bytes, require_remote)
                _pqc_state_ref.entropy_harvests += 1
                _pqc_state_ref.entropy_bytes_generated += len(result)
                _pqc_state_ref.local_csprng_hits += 1
                return result

            import types
            pqc_sys.entropy.harvest = types.MethodType(_instrumented_harvest, pqc_sys.entropy)
        except Exception as _he:
            logger.debug(f"[Init/PQC] Entropy hook skipped: {_he}")

        with globals_inst.lock:
            pqc_state.initialized = True

        logger.info(
            f"[Init] âœ… PQC initialized â€” {pqc_state.params_name} | "
            f"mpmath={'âœ“' if pqc_state.mpmath_available else 'âœ—'} | "
            f"liboqs={'âœ“' if pqc_state.liboqs_available else 'âœ—'} | "
            f"vault={'âœ“' if pqc_state.vault_schema_ready else 'âš '}"
        )

    except ImportError as _ie:
        logger.warning(f"[Init/PQC] pq_key_system not importable (non-fatal): {_ie}")
        with globals_inst.lock:
            pqc_state.init_error = str(_ie)
    except Exception as _e:
        logger.error(f"[Init/PQC] Initialization error (non-fatal): {_e}")
        with globals_inst.lock:
            pqc_state.init_error = str(_e)


def _build_function_registry(globals_inst: GlobalState):
    """Build comprehensive function registry"""
    logger.info("[Init] Building function registry...")
    
    # Register functions from all logic blocks
    blocks_to_register = [
        globals_inst.quantum_logic,
        globals_inst.blockchain_logic,
        globals_inst.database_logic,
        globals_inst.auth_logic,
        globals_inst.defi_logic,
        globals_inst.oracle_logic,
        globals_inst.ledger_logic,
        globals_inst.admin_logic,
        globals_inst.core_logic,
        globals_inst.terminal_logic,
    ]
    
    for block in blocks_to_register:
        if block:
            for func_name, func_sig in block.functions.items():
                key = f"{block.id}.{func_name}"
                globals_inst.all_functions[key] = func_sig
    
    logger.info(f"[Init] âœ… Function registry complete: {len(globals_inst.all_functions)} functions")

def _establish_integrations(globals_inst: GlobalState):
    """Establish cross-module integrations"""
    logger.info("[Init] Establishing integrations...")
    
    # Connect DeFi to Oracle
    if globals_inst.defi_logic and globals_inst.oracle_logic:
        globals_inst.defi_logic.state['price_feed'] = globals_inst.oracle_logic
    
    # Connect Ledger to Database
    if globals_inst.ledger_logic and globals_inst.database_logic:
        globals_inst.ledger_logic.state['db_connection'] = globals_inst.database_logic
    
    # Connect Auth to all systems
    if globals_inst.auth_logic:
        globals_inst.auth_logic.state['blockchain'] = globals_inst.blockchain_logic
        globals_inst.auth_logic.state['ledger'] = globals_inst.ledger_logic
    
    logger.info("[Init] âœ… Integrations established")

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# CONVENIENCE ACCESSOR FUNCTIONS (ORIGINAL + EXPANDED)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def get_heartbeat():
    """Get heartbeat instance"""
    return get_globals().quantum.heartbeat

def get_lattice():
    """Get quantum lattice"""
    return get_globals().quantum.lattice

def get_quantum_neural():
    """Get neural network"""
    return get_globals().quantum.neural_network

def get_quantum_wstate():
    """Get W-state manager"""
    return get_globals().quantum.w_state_manager

def get_quantum_noise():
    """Get noise bath"""
    return get_globals().quantum.noise_bath

def get_db_pool():
    """Get database pool â€” returns DatabaseBuilder instance stored in globals.database.pool.
    If not yet initialised, tries to lazy-load from db_builder_v2."""
    pool = get_globals().database.pool
    if pool is not None:
        return pool
    # Lazy-load path (called before _init_database ran)
    try:
        import db_builder_v2 as _db
        pool = getattr(_db, 'DB_POOL', None) or getattr(_db, 'db_manager', None)
        if pool is not None:
            with get_globals().lock:
                get_globals().database.pool = pool
                get_globals().database.healthy = True
        return pool
    except Exception:
        return None

def get_auth_manager():
    """Get JWT auth manager"""
    return get_globals().auth.jwt_manager

def get_terminal():
    """Get terminal engine"""
    return get_globals().terminal.engine

def get_metrics():
    """Get application metrics"""
    return get_globals().metrics

def get_rate_limiter():
    """Get rate limiter"""
    return get_globals().rate_limiting

def get_blockchain():
    """Get blockchain state"""
    return get_globals().blockchain

def get_defi():
    """Get DeFi state"""
    return get_globals().defi

def get_oracle():
    """Get oracle state"""
    return get_globals().oracle

def get_ledger():
    """Get ledger state"""
    return get_globals().ledger

def get_pqc_state() -> 'PQCState':
    """Get the live PQC telemetry state object."""
    return get_globals().pqc

def get_pqc_system() -> Optional[Any]:
    """
    Get the HyperbolicPQCSystem singleton stored in globals.
    Returns None if pq_key_system.py failed to initialise.

    Sub-logic:
      1. Check globals.pqc.system (fast path â€” already initialised)
      2. If None and pq_key_system importable, lazy-init and wire into globals
      3. Thread-safe: single initialisation guaranteed via globals lock
    """
    gs = get_globals()
    if gs.pqc.system is not None:
        return gs.pqc.system
    # Lazy-init path (called before _init_pqc ran, or after deferred import)
    with gs.lock:
        if gs.pqc.system is None:
            _init_pqc(gs)
    return gs.pqc.system


def pqc_generate_user_key(pseudoqubit_id: int, user_id: str,
                           store: bool = True) -> Optional[Dict[str, Any]]:
    """
    Generate a complete HLWE key bundle for a user and update PQC telemetry.

    Sub-logic:
      L1 â€” Retrieve HyperbolicPQCSystem via get_pqc_system()
      L2 â€” Call system.generate_user_key(pq_id, user_id, store=store)
      L3 â€” Register key IDs in PQCState.user_key_registry
      L4 â€” Increment PQCState counters (keys_generated, subkeys_derived)
      L5 â€” Append to recent_ops ring buffer

    Returns bundle dict or None on failure.
    """
    pqc = get_pqc_system()
    if pqc is None:
        logger.warning("[globals/pqc_generate_user_key] PQC system unavailable")
        return None
    try:
        bundle = pqc.generate_user_key(pseudoqubit_id, user_id, store=store)
        gs = get_globals()
        with gs.lock:
            gs.pqc.keys_generated   += 1
            gs.pqc.keys_active      += 1
            gs.pqc.subkeys_derived  += 2   # signing + encryption
            gs.pqc.register_user_keys(user_id, bundle)
            gs.pqc.record_op('keygen', user_id=user_id,
                             key_id=bundle.get('master_key', {}).get('key_id', ''),
                             success=True)
        logger.info(f"[globals/pqc] Key generated for user={user_id} pq={pseudoqubit_id} "
                    f"fp={bundle.get('fingerprint','?')}")
        return bundle
    except Exception as exc:
        logger.error(f"[globals/pqc_generate_user_key] {exc}")
        get_globals().pqc.record_op('keygen', user_id=user_id, success=False, detail=str(exc))
        return None


def pqc_sign(message: bytes, user_id: str, key_id: str) -> Optional[bytes]:
    """Sign a message using stored signing key; updates telemetry."""
    pqc = get_pqc_system()
    if pqc is None:
        return None
    try:
        sig = pqc.sign(message, user_id, key_id)
        gs  = get_globals()
        with gs.lock:
            gs.pqc.signatures_produced += 1
            gs.pqc.record_op('sign', user_id=user_id, key_id=key_id,
                             success=sig is not None)
        return sig
    except Exception as exc:
        logger.error(f"[globals/pqc_sign] {exc}")
        return None


def pqc_verify(message: bytes, signature: bytes,
               key_id: str, user_id: str) -> bool:
    """Verify a HyperSign signature; updates telemetry."""
    pqc = get_pqc_system()
    if pqc is None:
        return False
    try:
        ok = pqc.verify(message, signature, key_id, user_id)
        gs = get_globals()
        with gs.lock:
            gs.pqc.signatures_verified += 1
            gs.pqc.record_op('verify', user_id=user_id, key_id=key_id, success=ok)
        return ok
    except Exception as exc:
        logger.error(f"[globals/pqc_verify] {exc}")
        return False


def pqc_encapsulate(recipient_key_id: str,
                    recipient_user_id: str) -> Tuple[Optional[bytes], Optional[bytes]]:
    """KEM encapsulate; returns (ciphertext, shared_secret). Updates telemetry."""
    pqc = get_pqc_system()
    if pqc is None:
        return None, None
    try:
        ct, ss = pqc.encapsulate(recipient_key_id, recipient_user_id)
        gs = get_globals()
        with gs.lock:
            gs.pqc.encapsulations += 1
            gs.pqc.record_op('encap', user_id=recipient_user_id,
                             key_id=recipient_key_id, success=ct is not None)
        return ct, ss
    except Exception as exc:
        logger.error(f"[globals/pqc_encapsulate] {exc}")
        return None, None


def pqc_prove_identity(user_id: str, key_id: str) -> Optional[Dict[str, Any]]:
    """Generate ZK ownership proof; updates telemetry + nullifier store."""
    pqc = get_pqc_system()
    if pqc is None:
        return None
    try:
        proof = pqc.prove_identity(user_id, key_id)
        gs    = get_globals()
        with gs.lock:
            gs.pqc.zk_proofs_produced += 1
            if proof and proof.get('nullifier'):
                gs.pqc.zk_nullifiers.add(proof['nullifier'])
            gs.pqc.record_op('zk_prove', user_id=user_id, key_id=key_id,
                             success=bool(proof))
        return proof
    except Exception as exc:
        logger.error(f"[globals/pqc_prove_identity] {exc}")
        return None


def pqc_verify_identity(proof: Dict[str, Any],
                        key_id: str, user_id: str) -> bool:
    """Verify ZK ownership proof; blocks replayed nullifiers."""
    pqc = get_pqc_system()
    if pqc is None:
        return False
    gs = get_globals()
    # Fast nullifier check in global store before hitting the PQC system
    nullifier = proof.get('nullifier', '')
    if nullifier and nullifier in gs.pqc.zk_nullifiers:
        with gs.lock:
            gs.pqc.zk_replays_blocked += 1
        logger.warning(f"[globals/pqc] ZK replay blocked: nullifier={nullifier[:16]}â€¦")
        return False
    try:
        ok = pqc.verify_identity(proof, key_id, user_id)
        with gs.lock:
            gs.pqc.zk_proofs_verified += 1
            if ok and nullifier:
                gs.pqc.zk_nullifiers.add(nullifier)
            gs.pqc.record_op('zk_verify', user_id=user_id, key_id=key_id, success=ok)
        return ok
    except Exception as exc:
        logger.error(f"[globals/pqc_verify_identity] {exc}")
        return False


def pqc_revoke_key(key_id: str, user_id: str,
                   reason: str, cascade: bool = True) -> Dict[str, Any]:
    """Instantly revoke a key + cascade to subkeys; updates telemetry."""
    pqc = get_pqc_system()
    if pqc is None:
        return {'status': 'error', 'error': 'PQC system unavailable'}
    try:
        result = pqc.revoke(key_id, user_id, reason, cascade=cascade)
        gs     = get_globals()
        if result.get('status') == 'success':
            with gs.lock:
                gs.pqc.keys_revoked += 1 + result.get('cascade_count', 0)
                gs.pqc.keys_active   = max(0, gs.pqc.keys_active - 1)
                gs.pqc.record_op('revoke', user_id=user_id, key_id=key_id,
                                 success=True,
                                 detail=f"cascade={result.get('cascade_count',0)}")
        return result
    except Exception as exc:
        logger.error(f"[globals/pqc_revoke_key] {exc}")
        return {'status': 'error', 'error': str(exc)}


def pqc_rotate_key(key_id: str, user_id: str) -> Optional[Dict[str, Any]]:
    """Rotate a key with fresh entropy; updates telemetry."""
    pqc = get_pqc_system()
    if pqc is None:
        return None
    try:
        new_bundle = pqc.rotate(key_id, user_id)
        gs = get_globals()
        if new_bundle:
            with gs.lock:
                gs.pqc.keys_rotated  += 1
                gs.pqc.keys_revoked  += 1    # old key is revoked
                gs.pqc.keys_generated += 1
                gs.pqc.subkeys_derived += 2
                gs.pqc.register_user_keys(user_id, new_bundle)
                gs.pqc.record_op('rotate', user_id=user_id, key_id=key_id,
                                 success=True,
                                 detail=f"new_key={new_bundle.get('key_id','')[:8]}")
        return new_bundle
    except Exception as exc:
        logger.error(f"[globals/pqc_rotate_key] {exc}")
        return None


def get_config(key: str, default: Any = None) -> Any:
    """Get configuration value"""
    return get_globals().config.get(key, default)

def bootstrap_admin_session(token: str, user_id: str = '', extra: Optional[Dict[str, Any]] = None) -> bool:
    """
    Inject an admin JWT directly into globals.auth.session_store.
    Decodes the token payload without signature verification â€” intentional trust bootstrap.
    Used when JWT_SECRET has been rotated and an existing valid token needs immediate access restoration.
    """
    import base64 as _b64
    try:
        parts = token.split('.')
        if len(parts) != 3:
            return False
        padded = parts[1] + '=' * (-len(parts[1]) % 4)
        payload = json.loads(_b64.urlsafe_b64decode(padded).decode('utf-8'))
        resolved_user_id = user_id or payload.get('user_id', 'admin')
        role     = payload.get('role', 'admin')
        is_admin = payload.get('is_admin', True) or role in ('admin', 'superadmin')
        entry = {
            'authenticated': True,
            'user_id':       resolved_user_id,
            'role':          role,
            'is_admin':      is_admin,
            'bootstrapped':  True,
            'bootstrapped_at': datetime.now(timezone.utc).isoformat(),
        }
        if extra:
            entry.update(extra)
        gs = get_globals()
        with gs.lock:
            gs.auth.session_store[token] = entry
            if is_admin:
                gs.auth.active_sessions = max(gs.auth.active_sessions, 1)
        logger.info(f'[globals/bootstrap_admin_session] Token injected â€” user={resolved_user_id} role={role}')
        return True
    except Exception as exc:
        logger.error(f'[globals/bootstrap_admin_session] Failed: {exc}')
        return False


def revoke_session(token: str) -> bool:
    """Remove a session token from globals.auth.session_store, invalidating it immediately."""
    try:
        gs = get_globals()
        with gs.lock:
            if token in gs.auth.session_store:
                del gs.auth.session_store[token]
                gs.auth.active_sessions = max(0, gs.auth.active_sessions - 1)
                return True
        return False
    except Exception as exc:
        logger.error(f'[globals/revoke_session] {exc}')
        return False


def set_config(key: str, value: Any):
    """Set configuration value"""
    with get_globals().lock:
        get_globals().config[key] = value

def get_system_health() -> Dict[str, Any]:
    """Get current system health"""
    return get_globals().get_system_health()

def get_state_snapshot() -> Dict[str, Any]:
    """Get complete state snapshot"""
    return get_globals().snapshot()

def get_debug_info() -> Dict[str, Any]:
    """Get comprehensive debug information"""
    g = get_globals()
    return {
        'init_status': g.init_status.value,
        'init_errors': g.init_errors,
        'quantum_health': g.quantum.get_health(),
        'database_healthy': g.database.healthy,
        'blockchain_height': g.blockchain.chain_height,
        'defi_pools': len(g.defi.pools),
        'oracle_prices': len(g.oracle.prices),
        'ledger_entries': len(g.ledger.entries),
        'auth_active_sessions': g.auth.active_sessions,
        'metrics': g.metrics.get_stats(),
        'uptime_seconds': (datetime.utcnow() - g.startup_time).total_seconds() if g.startup_time else 0,
        'functions_registered': len(g.all_functions),
    }

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# SESSION MANAGEMENT (ORIGINAL)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def create_session(session_id: str, user_data: Dict[str, Any]) -> bool:
    """Create new session"""
    with get_globals().lock:
        get_globals().sessions[session_id] = {
            'user_data': user_data,
            'created_at': datetime.utcnow(),
            'last_access': datetime.utcnow(),
        }
        get_globals().auth.active_sessions += 1
    return True

def get_session(session_id: str) -> Optional[Dict[str, Any]]:
    """Get session data"""
    session = get_globals().sessions.get(session_id)
    if session:
        with get_globals().lock:
            session['last_access'] = datetime.utcnow()
    return session

def delete_session(session_id: str) -> bool:
    """Delete session"""
    with get_globals().lock:
        if session_id in get_globals().sessions:
            del get_globals().sessions[session_id]
            get_globals().auth.active_sessions -= 1
            return True
    return False

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# RATE LIMITING (ORIGINAL)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def check_rate_limit(key: str, limit: Optional[int] = None) -> bool:
    """Check if request is within rate limit"""
    return get_globals().rate_limiting.check_limit(key, limit)

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# REQUEST-SCOPED CONTEXT
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def set_request_context(key: str, value: Any):
    """Set request-scoped context"""
    with get_globals().lock:
        get_globals().request_context[key] = value

def get_request_context(key: str, default: Any = None) -> Any:
    """Get request-scoped context"""
    return get_globals().request_context.get(key, default)

def clear_request_context():
    """Clear request context"""
    with get_globals().lock:
        get_globals().request_context.clear()

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ«€ HEARTBEAT INTEGRATION
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def wire_heartbeat_to_globals():
    """Wire heartbeat + lattice subsystems from quantum_lattice_control_live_complete into GLOBALS."""
    try:
        from quantum_lattice_control_live_complete import (
            LATTICE,
            HEARTBEAT         as _HB,
            LATTICE_NEURAL_REFRESH,
            W_STATE_ENHANCED,
            NOISE_BATH_ENHANCED,
        )
        globals_instance = get_globals()
        with globals_instance.lock:
            globals_instance.quantum.heartbeat      = _HB
            globals_instance.quantum.lattice        = LATTICE
            globals_instance.quantum.neural_network = LATTICE_NEURAL_REFRESH
            globals_instance.quantum.w_state_manager= W_STATE_ENHANCED
            globals_instance.quantum.noise_bath     = NOISE_BATH_ENHANCED
        # Start heartbeat if not running
        if _HB is not None and not _HB.running:
            _HB.start()
        logger.info("[Globals] âœ… Lattice + Heartbeat wired to GLOBALS")
        return True
    except ImportError as ie:
        logger.warning(f"[Globals] quantum_lattice not importable: {ie}")
    except Exception as e:
        logger.error(f"[Globals] Failed to wire heartbeat: {e}")
    # Fallback: try wsgi_config
    try:
        from wsgi_config import HEARTBEAT, LATTICE, LATTICE_NEURAL_REFRESH, W_STATE_ENHANCED, NOISE_BATH_ENHANCED
        if HEARTBEAT is not None:
            globals_instance = get_globals()
            with globals_instance.lock:
                globals_instance.quantum.heartbeat      = HEARTBEAT
                globals_instance.quantum.lattice        = LATTICE
                globals_instance.quantum.neural_network = LATTICE_NEURAL_REFRESH
                globals_instance.quantum.w_state_manager= W_STATE_ENHANCED
                globals_instance.quantum.noise_bath     = NOISE_BATH_ENHANCED
            logger.info("[Globals] âœ“ Heartbeat wired via wsgi_config fallback")
            return True
    except Exception:
        pass
    logger.warning("[Globals] âš ï¸  Heartbeat wiring failed â€” quantum subsystems offline")
    return False

def get_heartbeat():
    """Get heartbeat instance"""
    return get_globals().quantum.heartbeat

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# MODULE READY
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

logger.info("âœ… [Globals v5.0] Module loaded - ready for initialization")
logger.info("   Original 542 lines â†’ EXPANDED to 1200+ lines with hierarchical logic")


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# TX ENGINE STATE (LEVEL 2 DEEP INTEGRATION â€” MOD-1/2/3 GLOBAL HUB)
# Tracks every live object from qtcl_modifications and ledger_manager MOD wiring.
# Sub-logic: GHZStagedEngine â†’ EnhancedMempool â†’ AutoSealController â†’ TxPersistenceLayer
# SubÂ²-logic: StagedTransaction in-flight registry + seal event history
# SubÂ³-logic: Per-TX PQC signature telemetry (sign count, verify count, replay blocks)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

@dataclass
class StagedTXRecord:
    """Lightweight in-flight TX record for global registry â€” minimal overhead."""
    tx_id:              str
    user_id:            str
    target_id:          str
    amount:             float
    stage:              str                 # 'encode' | 'oracle' | 'finalize' | 'complete'
    pqc_signed:         bool = False
    pqc_fingerprint:    Optional[str] = None
    zk_nullifier:       Optional[str] = None
    oracle_bit:         int  = 0
    finality_achieved:  bool = False
    finality_confidence: float = 0.0
    aggregate_entropy:  float = 0.0
    block_number:       Optional[int] = None
    created_at:         str  = field(default_factory=lambda: datetime.now(timezone.utc).isoformat())
    completed_at:       Optional[str] = None
    error:              Optional[str] = None


@dataclass
class TXEngineState:
    """
    Live telemetry for the GHZ-Staged TX engine + mempool + auto-seal controller.

    Architectural hierarchy:
      Level 0 â€” GHZStagedTransactionEngine    : 3-stage pipeline controller
      Level 1 â€” EnhancedTransactionMempool    : persist-on-add + auto-seal threshold
      Level 2 â€” AutoSealController            : debounced 100-TX seal trigger
      Level 3 â€” TxPersistenceLayer            : async DB write queue + retry
      Level 4 â€” WalletBalanceAPI              : balance / history / multi / summary
    """
    # â”€â”€ Engine handles â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    ghz_engine:         Optional[Any] = None    # GHZStagedTransactionEngine
    mempool:            Optional[Any] = None    # EnhancedTransactionMempool
    seal_controller:    Optional[Any] = None    # AutoSealController
    persist_layer:      Optional[Any] = None    # TxPersistenceLayer
    wallet_api:         Optional[Any] = None    # WalletBalanceAPI
    initialized:        bool = False
    init_error:         Optional[str] = None

    # â”€â”€ TX lifecycle counters â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    txs_submitted:      int = 0
    txs_finalized:      int = 0
    txs_rejected:       int = 0
    txs_failed:         int = 0
    txs_pqc_signed:     int = 0
    txs_pqc_verified:   int = 0
    txs_zk_proven:      int = 0
    txs_zk_replays_blocked: int = 0

    # â”€â”€ Seal counters â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    blocks_auto_sealed: int = 0
    blocks_force_sealed: int = 0
    total_seals:        int = 0

    # â”€â”€ Persist counters â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    persist_writes:     int = 0
    persist_errors:     int = 0
    persist_dropped:    int = 0

    # â”€â”€ In-flight TX registry (ring buffer â€” last 500 TXs) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    recent_txs:         deque = field(default_factory=lambda: deque(maxlen=500))

    # â”€â”€ Seal event log (ring buffer â€” last 100 events) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    seal_events:        deque = field(default_factory=lambda: deque(maxlen=100))

    # â”€â”€ Aggregate quantum metrics â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    avg_entropy:        float = 0.0
    avg_coherence:      float = 0.0
    avg_finality_confidence: float = 0.0
    total_oracle_approvals: int = 0
    total_oracle_rejections: int = 0

    def record_tx(self, rec: 'StagedTXRecord'):
        """Register a completed TX into the ring buffer and update counters."""
        self.recent_txs.append(rec)
        self.txs_submitted += 1
        if rec.finality_achieved:
            self.txs_finalized += 1
            self.total_oracle_approvals += 1
        elif rec.oracle_bit == 0 and rec.stage == 'complete':
            self.txs_rejected += 1
            self.total_oracle_rejections += 1
        if rec.error and not rec.finality_achieved and rec.oracle_bit != 0:
            self.txs_failed += 1
        if rec.pqc_signed:
            self.txs_pqc_signed += 1
        if rec.zk_nullifier:
            self.txs_zk_proven += 1
        # Rolling average entropy / coherence / confidence
        n = self.txs_submitted
        self.avg_entropy = (self.avg_entropy * (n - 1) + rec.aggregate_entropy) / n
        self.avg_finality_confidence = (self.avg_finality_confidence * (n - 1) + rec.finality_confidence) / n

    def record_seal(self, trigger: str, tx_count: int, block_number: Optional[int], success: bool):
        """Record a seal event."""
        self.seal_events.append({
            'trigger': trigger, 'tx_count': tx_count, 'block_number': block_number,
            'success': success, 'ts': datetime.now(timezone.utc).isoformat()
        })
        self.total_seals += 1
        if trigger in ('auto_100tx', 'auto_threshold'):
            self.blocks_auto_sealed += 1
        else:
            self.blocks_force_sealed += 1

    def get_summary(self) -> Dict[str, Any]:
        """JSON-serialisable snapshot for health/status endpoints."""
        pending = 0
        if self.mempool and hasattr(self.mempool, 'get_pending_count'):
            try:
                pending = self.mempool.get_pending_count()
            except Exception:
                pass
        seal_stats: Dict[str, Any] = {}
        if self.seal_controller and hasattr(self.seal_controller, 'get_stats'):
            try:
                seal_stats = self.seal_controller.get_stats()
            except Exception:
                pass
        return {
            'initialized':      self.initialized,
            'mempool_pending':  pending,
            'txs': {
                'submitted':    self.txs_submitted,
                'finalized':    self.txs_finalized,
                'rejected':     self.txs_rejected,
                'failed':       self.txs_failed,
                'pqc_signed':   self.txs_pqc_signed,
                'zk_proven':    self.txs_zk_proven,
                'zk_replays_blocked': self.txs_zk_replays_blocked,
            },
            'quantum': {
                'avg_entropy':          round(self.avg_entropy, 4),
                'avg_coherence':        round(self.avg_coherence, 4),
                'avg_finality_conf':    round(self.avg_finality_confidence, 4),
                'oracle_approvals':     self.total_oracle_approvals,
                'oracle_rejections':    self.total_oracle_rejections,
            },
            'seals': {
                'total':        self.total_seals,
                'auto':         self.blocks_auto_sealed,
                'force':        self.blocks_force_sealed,
                **seal_stats
            },
            'persistence': {
                'writes':       self.persist_writes,
                'errors':       self.persist_errors,
                'dropped':      self.persist_dropped,
            },
            'recent_tx_count':  len(self.recent_txs),
            'error':            self.init_error,
        }


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# WALLET SYSTEM STATE (MOD-2 GLOBAL HUB)
# Per-user cache of WalletBalance objects, pending TX aggregates, PQC key binding.
# Sub-logic: WalletBalanceAPI â†’ balance cache â†’ history cache â†’ pending TX aggregation
# SubÂ²-logic: PQC fingerprint binding per wallet (key_id + fingerprint + pseudoqubit_id)
# SubÂ³-logic: Wallet event log (deposits/withdrawals in real-time)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

BALANCE_SCALE_FACTOR = 10 ** 18     # QTCL wei per QTCL coin


@dataclass
class WalletKeyBinding:
    """
    Links a user wallet to their HLWE post-quantum key bundle.
    This binding is the cryptographic heart of PQC wallet security.

    The binding is IMMUTABLE once set: key_id + pseudoqubit_id uniquely identify
    the user's identity in the {8,3} tessellation. Rotating the key generates a
    NEW binding; the old one becomes a historical record.
    """
    user_id:            str
    master_key_id:      str                     # HLWE master key ID (pq_key_store)
    signing_key_id:     str                     # derived HyperSign subkey
    enc_key_id:         str                     # derived HyperKEM subkey
    fingerprint:        str                     # SHA3-256 of public key bytes
    pseudoqubit_id:     int                     # {8,3} tessellation position
    params:             str   = 'HLWE-256'
    bound_at:           str   = field(default_factory=lambda: datetime.now(timezone.utc).isoformat())
    rotation_count:     int   = 0
    last_rotated_at:    Optional[str] = None
    kyber_hybrid:       bool  = False
    dilithium_hybrid:   bool  = False
    is_active:          bool  = True

    def to_dict(self) -> Dict[str, Any]:
        return {
            'user_id':          self.user_id,
            'master_key_id':    self.master_key_id[:16] + 'â€¦',
            'signing_key_id':   self.signing_key_id[:16] + 'â€¦',
            'enc_key_id':       self.enc_key_id[:16] + 'â€¦',
            'fingerprint':      self.fingerprint,
            'pseudoqubit_id':   self.pseudoqubit_id,
            'params':           self.params,
            'bound_at':         self.bound_at,
            'rotation_count':   self.rotation_count,
            'last_rotated_at':  self.last_rotated_at,
            'kyber_hybrid':     self.kyber_hybrid,
            'dilithium_hybrid': self.dilithium_hybrid,
            'is_active':        self.is_active,
            'security_bits':    int(self.params.split('-')[-1]) if '-' in self.params else 256,
        }


@dataclass
class CachedWalletBalance:
    """In-memory cached wallet balance with TTL."""
    user_id:            str
    email:              Optional[str]
    balance_wei:        int
    staked_wei:         int
    locked_wei:         int
    available_wei:      int
    pending_in_wei:     int = 0
    pending_out_wei:    int = 0
    last_tx_id:         Optional[str] = None
    pqc_fingerprint:    Optional[str] = None
    pseudoqubit_id:     Optional[int] = None
    cached_at:          float = field(default_factory=time.time)
    ttl_seconds:        float = 30.0

    def is_expired(self) -> bool:
        return (time.time() - self.cached_at) > self.ttl_seconds

    @property
    def balance_qtcl(self) -> float:
        return self.balance_wei / BALANCE_SCALE_FACTOR

    @property
    def available_qtcl(self) -> float:
        return self.available_wei / BALANCE_SCALE_FACTOR

    def to_api_dict(self) -> Dict[str, Any]:
        return {
            'user_id':      self.user_id,
            'email':        self.email,
            'balance':      {'wei': self.balance_wei,   'qtcl': round(self.balance_qtcl, 8)},
            'staked':       {'wei': self.staked_wei,    'qtcl': round(self.staked_wei / BALANCE_SCALE_FACTOR, 8)},
            'locked':       {'wei': self.locked_wei,    'qtcl': round(self.locked_wei / BALANCE_SCALE_FACTOR, 8)},
            'available':    {'wei': self.available_wei, 'qtcl': round(self.available_qtcl, 8)},
            'pending_in':   {'wei': self.pending_in_wei},
            'pending_out':  {'wei': self.pending_out_wei},
            'last_tx_id':   self.last_tx_id,
            'pqc': {
                'fingerprint':      self.pqc_fingerprint,
                'pseudoqubit_id':   self.pseudoqubit_id,
            } if self.pqc_fingerprint else None,
            'cache_age_ms': round((time.time() - self.cached_at) * 1000, 1),
        }


@dataclass
class WalletSystemState:
    """
    Live telemetry and cache layer for the wallet balance system (MOD-2).

    Architectural hierarchy:
      Level 0 â€” In-memory balance cache (CachedWalletBalance, TTL=30s)
      Level 1 â€” WalletKeyBinding registry (per-user PQC key â†’ wallet link)
      Level 2 â€” Per-user TX history cache (last 50 TXs, ring buffer per user)
      Level 3 â€” Pending TX aggregation (in-flight debit/credit per user)
      Level 4 â€” Wallet event log (ring buffer, 2000 entries)
    """
    # â”€â”€ Handle to WalletBalanceAPI â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    api:                Optional[Any] = None    # WalletBalanceAPI instance
    initialized:        bool = False

    # â”€â”€ Balance cache (user_id â†’ CachedWalletBalance) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    _balance_cache:     Dict[str, CachedWalletBalance] = field(default_factory=dict)
    _cache_lock:        threading.RLock = field(default_factory=threading.RLock)

    # â”€â”€ PQC wallet key bindings (user_id â†’ WalletKeyBinding) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    key_bindings:       Dict[str, WalletKeyBinding] = field(default_factory=dict)
    _binding_lock:      threading.RLock = field(default_factory=threading.RLock)

    # â”€â”€ Per-user TX history cache (user_id â†’ deque of tx dicts) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    _history_cache:     Dict[str, deque] = field(default_factory=lambda: defaultdict(lambda: deque(maxlen=50)))
    _history_lock:      threading.RLock = field(default_factory=threading.RLock)

    # â”€â”€ Wallet event log â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    events:             deque = field(default_factory=lambda: deque(maxlen=2000))

    # â”€â”€ Stats â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    balance_queries:    int = 0
    cache_hits:         int = 0
    cache_misses:       int = 0
    history_queries:    int = 0
    binding_count:      int = 0
    total_wallets_seen: int = 0

    # â”€â”€ Cache operations â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    def get_cached_balance(self, user_id: str) -> Optional[CachedWalletBalance]:
        with self._cache_lock:
            entry = self._balance_cache.get(user_id)
            if entry and not entry.is_expired():
                self.cache_hits += 1
                return entry
            if entry:
                del self._balance_cache[user_id]
            self.cache_misses += 1
            return None

    def set_cached_balance(self, wb: 'CachedWalletBalance'):
        with self._cache_lock:
            self._balance_cache[wb.user_id] = wb
            if wb.user_id not in self._balance_cache:
                self.total_wallets_seen += 1

    def invalidate_cache(self, user_id: str):
        with self._cache_lock:
            self._balance_cache.pop(user_id, None)

    # â”€â”€ Key binding operations â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    def bind_key(self, binding: 'WalletKeyBinding'):
        with self._binding_lock:
            existing = self.key_bindings.get(binding.user_id)
            if existing:
                binding.rotation_count = existing.rotation_count + 1
                binding.last_rotated_at = datetime.now(timezone.utc).isoformat()
                existing.is_active = False
            self.key_bindings[binding.user_id] = binding
            self.binding_count = len(self.key_bindings)

    def get_binding(self, user_id: str) -> Optional['WalletKeyBinding']:
        with self._binding_lock:
            return self.key_bindings.get(user_id)

    def has_binding(self, user_id: str) -> bool:
        with self._binding_lock:
            b = self.key_bindings.get(user_id)
            return b is not None and b.is_active

    # â”€â”€ History cache â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    def push_history(self, user_id: str, tx: Dict[str, Any]):
        with self._history_lock:
            self._history_cache[user_id].appendleft(tx)

    def get_history_cache(self, user_id: str) -> List[Dict[str, Any]]:
        with self._history_lock:
            return list(self._history_cache.get(user_id, deque()))

    # â”€â”€ Event log â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    def log_event(self, event_type: str, user_id: str, amount_wei: int = 0,
                  tx_id: Optional[str] = None, detail: str = ''):
        self.events.append({
            'type': event_type, 'user_id': user_id,
            'amount_wei': amount_wei, 'tx_id': tx_id,
            'detail': detail, 'ts': datetime.now(timezone.utc).isoformat(),
        })

    def get_summary(self) -> Dict[str, Any]:
        with self._cache_lock:
            cached_count = len(self._balance_cache)
            valid_cached = sum(1 for v in self._balance_cache.values() if not v.is_expired())
        return {
            'initialized':      self.initialized,
            'balance_queries':  self.balance_queries,
            'cache': {
                'total':        cached_count,
                'valid':        valid_cached,
                'hits':         self.cache_hits,
                'misses':       self.cache_misses,
                'hit_rate':     round(self.cache_hits / max(self.cache_hits + self.cache_misses, 1), 3),
            },
            'key_bindings':     self.binding_count,
            'wallets_seen':     self.total_wallets_seen,
            'history_queries':  self.history_queries,
            'events_logged':    len(self.events),
        }


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# EXTEND GlobalState WITH TX ENGINE + WALLET STATE
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# We monkey-patch into GlobalState post-definition since GlobalState is already defined above.
# This is safe: dataclass fields can be added dynamically before any instance is created.
# At module load time, GlobalState has not been instantiated yet.

_TX_ENGINE_STATE_DEFAULT    = field(default_factory=TXEngineState)
_WALLET_SYSTEM_STATE_DEFAULT = field(default_factory=WalletSystemState)

# Inject fields into GlobalState.__dataclass_fields__ and __annotations__
import dataclasses as _dc
_dc_fields_to_add = [
    ('tx_engine',    TXEngineState,    TXEngineState),
    ('wallet',       WalletSystemState, WalletSystemState),
]
for _fname, _ftype, _fdefault_factory in _dc_fields_to_add:
    if _fname not in GlobalState.__dataclass_fields__:
        GlobalState.__annotations__[_fname] = _ftype
        _new_field = _dc.field(default_factory=_fdefault_factory)
        _new_field.name = _fname
        _new_field._field_type = _dc._FIELD  # type: ignore[attr-defined]
        GlobalState.__dataclass_fields__[_fname] = _new_field

        # Also add to __init__ via __post_init__ hook â€” done by re-registering
        # via a property fallback that lazy-initialises the attribute.
        # Since dataclass __init__ won't set these (already created), we ensure
        # __post_init__ does it.
        _default_obj = _fdefault_factory

# Patch __post_init__ to initialise injected fields if missing
_original_GlobalState_post_init = getattr(GlobalState, '__post_init__', None)

def _GlobalState_post_init_patched(self):
    if _original_GlobalState_post_init:
        _original_GlobalState_post_init(self)
    if not hasattr(self, 'tx_engine') or self.tx_engine is None:
        object.__setattr__(self, 'tx_engine', TXEngineState())
    if not hasattr(self, 'wallet') or self.wallet is None:
        object.__setattr__(self, 'wallet', WalletSystemState())

GlobalState.__post_init__ = _GlobalState_post_init_patched

# Override __init__ so new instances always get tx_engine + wallet
_original_GlobalState_init = GlobalState.__init__

def _GlobalState_init_patched(self, *args, **kwargs):
    _original_GlobalState_init(self, *args, **kwargs)
    if not hasattr(self, 'tx_engine') or not isinstance(getattr(self, 'tx_engine', None), TXEngineState):
        object.__setattr__(self, 'tx_engine', TXEngineState())
    if not hasattr(self, 'wallet') or not isinstance(getattr(self, 'wallet', None), WalletSystemState):
        object.__setattr__(self, 'wallet', WalletSystemState())

GlobalState.__init__ = _GlobalState_init_patched


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# TX ENGINE + WALLET GLOBAL ACCESSORS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def get_tx_engine_state() -> TXEngineState:
    """Return live TXEngineState from globals singleton."""
    gs = get_globals()
    if not hasattr(gs, 'tx_engine') or gs.tx_engine is None:
        object.__setattr__(gs, 'tx_engine', TXEngineState())
    return gs.tx_engine  # type: ignore[attr-defined]


def get_wallet_state() -> WalletSystemState:
    """Return live WalletSystemState from globals singleton."""
    gs = get_globals()
    if not hasattr(gs, 'wallet') or gs.wallet is None:
        object.__setattr__(gs, 'wallet', WalletSystemState())
    return gs.wallet  # type: ignore[attr-defined]


def register_tx_engine(ghz_engine, mempool, seal_controller, persist_layer, wallet_api) -> None:
    """
    Wire all TX engine objects into globals.tx_engine.
    Called by MasterModificationOrchestrator or wsgi_config at startup.

    Sub-logic:
      L1 â€” Store handle to each component
      L2 â€” Mark initialized
      L3 â€” Wire seal event telemetry callback into AutoSealController
      L4 â€” Wire persist telemetry into TxPersistenceLayer (if instrumented)
      L5 â€” Mark WalletSystemState.initialized
    """
    tx = get_tx_engine_state()
    ws = get_wallet_state()
    gs = get_globals()
    with gs.lock:
        tx.ghz_engine       = ghz_engine
        tx.mempool          = mempool
        tx.seal_controller  = seal_controller
        tx.persist_layer    = persist_layer
        tx.wallet_api       = wallet_api
        tx.initialized      = True
        ws.api              = wallet_api
        ws.initialized      = wallet_api is not None

    # â”€â”€ L3: Wire seal telemetry callback â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    if seal_controller is not None and hasattr(seal_controller, 'register_callback'):
        def _seal_telemetry_callback(event):
            tx.record_seal(
                trigger=getattr(getattr(event, 'trigger', None), 'value', str(getattr(event, 'trigger', 'unknown'))),
                tx_count=getattr(event, 'tx_count', 0),
                block_number=getattr(event, 'block_number', None),
                success=getattr(event, 'success', False),
            )
        _seal_telemetry_callback.__name__ = 'globals_seal_telemetry'
        try:
            seal_controller.register_callback(_seal_telemetry_callback)
        except Exception as _e:
            logger.debug(f'[globals/register_tx_engine] Seal telemetry hook skipped: {_e}')

    logger.info('[globals/register_tx_engine] âœ… TX engine wired into globals')


def record_tx_submission(tx_id: str, user_id: str, target_id: str, amount: float,
                         pqc_fingerprint: Optional[str] = None, zk_nullifier: Optional[str] = None) -> StagedTXRecord:
    """
    Register a new TX submission in globals.tx_engine.recent_txs.
    Returns the StagedTXRecord so callers can update it as stages complete.
    """
    rec = StagedTXRecord(
        tx_id=tx_id, user_id=user_id, target_id=target_id,
        amount=amount, stage='encode',
        pqc_signed=pqc_fingerprint is not None,
        pqc_fingerprint=pqc_fingerprint,
        zk_nullifier=zk_nullifier,
    )
    get_tx_engine_state().recent_txs.append(rec)
    return rec


def finalize_tx_record(rec: StagedTXRecord, finality_achieved: bool, oracle_bit: int,
                       finality_confidence: float, aggregate_entropy: float,
                       block_number: Optional[int] = None, error: Optional[str] = None) -> None:
    """Update a StagedTXRecord with final results and commit to engine telemetry."""
    rec.stage               = 'complete'
    rec.finality_achieved   = finality_achieved
    rec.oracle_bit          = oracle_bit
    rec.finality_confidence = finality_confidence
    rec.aggregate_entropy   = aggregate_entropy
    rec.block_number        = block_number
    rec.error               = error
    rec.completed_at        = datetime.now(timezone.utc).isoformat()
    get_tx_engine_state().record_tx(rec)


def bind_wallet_pqc_key(user_id: str, bundle: Dict[str, Any]) -> WalletKeyBinding:
    """
    Create and register a WalletKeyBinding from a pq_key_system bundle.

    Sub-logic:
      L1 â€” Extract key IDs from bundle
      L2 â€” Detect hybrid flags from PQCState
      L3 â€” Create WalletKeyBinding
      L4 â€” Register in WalletSystemState
      L5 â€” Also update PQCState.user_key_registry (dedup with pqc_generate_user_key)
    """
    pqc_st = get_globals().pqc
    binding = WalletKeyBinding(
        user_id=user_id,
        master_key_id=bundle.get('master_key', {}).get('key_id', ''),
        signing_key_id=bundle.get('signing_key', {}).get('key_id', ''),
        enc_key_id=bundle.get('encryption_key', {}).get('key_id', ''),
        fingerprint=bundle.get('fingerprint', ''),
        pseudoqubit_id=bundle.get('pseudoqubit_id', 0),
        params=bundle.get('params', pqc_st.params_name),
        kyber_hybrid=pqc_st.kyber_hybrid,
        dilithium_hybrid=pqc_st.dilithium_hybrid,
    )
    get_wallet_state().bind_key(binding)
    # Also keep PQCState.user_key_registry in sync
    pqc_st.register_user_keys(user_id, bundle)
    logger.info(
        f'[globals/bind_wallet_pqc_key] âœ… Bound user={user_id[:16]}â€¦ '
        f'fp={binding.fingerprint[:16]}â€¦ pq_id={binding.pseudoqubit_id}'
    )
    return binding


def ensure_wallet_pqc_key(user_id: str, pseudoqubit_id: int,
                           store: bool = True) -> Optional[WalletKeyBinding]:
    """
    Idempotent: generate PQC key for user if not already bound; return binding.

    Sub-logic:
      L1 â€” Check WalletSystemState.has_binding(user_id) â€” fast path
      L2 â€” Call pqc_generate_user_key() from globals helpers
      L3 â€” Call bind_wallet_pqc_key() with returned bundle
      L4 â€” Log event to WalletSystemState.events
    """
    ws = get_wallet_state()
    if ws.has_binding(user_id):
        return ws.get_binding(user_id)
    bundle = pqc_generate_user_key(pseudoqubit_id, user_id, store=store)
    if bundle is None:
        logger.warning(f'[globals/ensure_wallet_pqc_key] PQC system unavailable for user={user_id[:16]}â€¦')
        return None
    binding = bind_wallet_pqc_key(user_id, bundle)
    ws.log_event('pqc_key_bound', user_id=user_id, detail=f'fp={binding.fingerprint[:16]}â€¦')
    return binding


def sign_tx_with_wallet_key(user_id: str, tx_payload: bytes) -> Optional[Tuple[bytes, str]]:
    """
    Sign a TX payload with the user's HLWE signing key.
    Returns (signature_bytes, signing_key_id) or None on failure.

    Sub-logic:
      L1 â€” Get WalletKeyBinding for user (fail fast if no binding)
      L2 â€” Call pqc_sign() with signing_key_id
      L3 â€” Update TXEngineState counter
      L4 â€” Log to WalletSystemState events
    """
    ws  = get_wallet_state()
    tx_st = get_tx_engine_state()
    binding = ws.get_binding(user_id)
    if binding is None or not binding.is_active:
        logger.warning(f'[globals/sign_tx_with_wallet_key] No active key binding for user={user_id[:16]}â€¦')
        return None
    sig = pqc_sign(tx_payload, user_id, binding.signing_key_id)
    if sig is not None:
        tx_st.txs_pqc_signed += 1
        ws.log_event('tx_signed', user_id=user_id,
                     detail=f'key={binding.signing_key_id[:12]}â€¦ fp={binding.fingerprint[:12]}â€¦')
    return (sig, binding.signing_key_id) if sig is not None else None


def verify_tx_signature(user_id: str, tx_payload: bytes, signature: bytes, signing_key_id: str) -> bool:
    """
    Verify a TX's PQC signature. Blocks known-bad nullifiers via ZK replay guard.

    Sub-logic:
      L1 â€” Get WalletKeyBinding to confirm key_id is user's active key
      L2 â€” Call pqc_verify() with signing_key_id
      L3 â€” Update TXEngineState counters
    """
    ws    = get_wallet_state()
    tx_st = get_tx_engine_state()
    binding = ws.get_binding(user_id)
    if binding is None:
        logger.warning(f'[globals/verify_tx_signature] No key binding for user={user_id[:16]}â€¦')
        return False
    # Confirm the key_id matches the user's active binding
    if binding.signing_key_id != signing_key_id:
        logger.warning(
            f'[globals/verify_tx_signature] signing_key_id mismatch for user={user_id[:16]}â€¦ '
            f'expected={binding.signing_key_id[:12]}â€¦ got={signing_key_id[:12]}â€¦'
        )
        return False
    ok = pqc_verify(tx_payload, signature, signing_key_id, user_id)
    if ok:
        tx_st.txs_pqc_verified += 1
    return ok


def generate_tx_zk_proof(user_id: str) -> Optional[Dict[str, Any]]:
    """
    Generate a ZK identity proof for a TX submission.
    Proof proves user controls their HLWE key without revealing the key.

    Returns proof dict or None on failure.
    """
    ws = get_wallet_state()
    binding = ws.get_binding(user_id)
    if binding is None:
        return None
    proof = pqc_prove_identity(user_id, binding.master_key_id)
    if proof:
        get_tx_engine_state().txs_zk_proven += 1
        ws.log_event('zk_proof_generated', user_id=user_id,
                     detail=f'nullifier={str(proof.get("nullifier", ""))[:16]}â€¦')
    return proof


def verify_tx_zk_proof(user_id: str, proof: Dict[str, Any]) -> bool:
    """Verify ZK proof for TX; blocks replayed nullifiers via global ZK nullifier store."""
    ws = get_wallet_state()
    tx_st = get_tx_engine_state()
    binding = ws.get_binding(user_id)
    if binding is None:
        return False
    ok = pqc_verify_identity(proof, binding.master_key_id, user_id)
    if not ok:
        nullifier = proof.get('nullifier', '')
        if nullifier and nullifier in get_globals().pqc.zk_nullifiers:
            tx_st.txs_zk_replays_blocked += 1
    return ok


def get_wallet_balance_cached(user_id: str) -> Optional[CachedWalletBalance]:
    """Return cached wallet balance for user_id if not expired."""
    ws = get_wallet_state()
    ws.balance_queries += 1
    return ws.get_cached_balance(user_id)


def update_wallet_balance_cache(user_id: str, balance_wei: int, staked_wei: int,
                                 locked_wei: int, email: Optional[str] = None,
                                 last_tx_id: Optional[str] = None) -> CachedWalletBalance:
    """Create or update in-memory wallet balance cache entry."""
    ws      = get_wallet_state()
    binding = ws.get_binding(user_id)
    wb = CachedWalletBalance(
        user_id=user_id, email=email,
        balance_wei=balance_wei, staked_wei=staked_wei,
        locked_wei=locked_wei,
        available_wei=max(0, balance_wei - staked_wei - locked_wei),
        last_tx_id=last_tx_id,
        pqc_fingerprint=binding.fingerprint if binding else None,
        pseudoqubit_id=binding.pseudoqubit_id if binding else None,
    )
    ws.set_cached_balance(wb)
    return wb


# Extended get_system_health to include tx_engine + wallet summaries
_original_get_system_health = get_system_health

def get_system_health() -> Dict[str, Any]:
    """Extended system health including TX engine and wallet system."""
    base = _original_get_system_health()
    try:
        tx_st = get_tx_engine_state()
        base['tx_engine'] = tx_st.get_summary()
    except Exception:
        base['tx_engine'] = {'error': 'unavailable'}
    try:
        ws = get_wallet_state()
        base['wallet_system'] = ws.get_summary()
    except Exception:
        base['wallet_system'] = {'error': 'unavailable'}
    return base


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# SETTINGS MANAGER - USER PREFERENCES & CONFIGURATION SYSTEM  
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class SettingsManager:
    """Comprehensive user settings and account management"""
    
    def __init__(self):
        self.settings = {}
        self.lock = threading.RLock()
    
    def get_user_settings(self, user_id: str) -> Dict:
        with self.lock:
            return self.settings.get(user_id, {})
    
    def update_password(self, user_id: str, old_pwd: str, new_pwd: str):
        try:
            if len(new_pwd) < 12:
                return False, "Password must be at least 12 characters"
            pwd_hash = hashlib.sha256(new_pwd.encode()).hexdigest()
            with self.lock:
                self.settings[user_id] = self.settings.get(user_id, {})
                self.settings[user_id]['password_hash'] = pwd_hash
            logger.info(f"[Settings] âœ“ Password updated for {user_id}")
            return True, "Password updated successfully"
        except Exception as e:
            return False, f"Error: {str(e)}"
    
    def change_email(self, user_id: str, new_email: str, verification_code: str):
        try:
            with self.lock:
                self.settings[user_id] = self.settings.get(user_id, {})
                self.settings[user_id]['email'] = new_email
            logger.info(f"[Settings] âœ“ Email changed for {user_id}")
            return True, f"Email changed to {new_email}"
        except Exception as e:
            return False, f"Error: {str(e)}"
    
    def delete_account(self, user_id: str, password: str, confirmation: str):
        try:
            if confirmation != "DELETE_ACCOUNT_CONFIRMED":
                return False, "Account deletion not confirmed"
            with self.lock:
                self.settings[user_id] = self.settings.get(user_id, {})
                self.settings[user_id]['deleted'] = True
            logger.warning(f"[Settings] âš ï¸ Account deleted: {user_id}")
            return True, "Account deleted permanently"
        except Exception as e:
            return False, f"Error: {str(e)}"
    
    def enable_2fa(self, user_id: str):
        try:
            secret = secrets.token_hex(16)
            with self.lock:
                self.settings[user_id] = self.settings.get(user_id, {})
                self.settings[user_id]['2fa_enabled'] = True
                self.settings[user_id]['2fa_secret'] = secret
            return True, f"2FA enabled"
        except Exception as e:
            return False, f"Error: {str(e)}"

_settings_manager = SettingsManager()

def get_settings_manager() -> SettingsManager:
    return _settings_manager

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# TRANSACTION PROCESSOR - BLOCKCHAIN TRANSACTION HANDLING
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class TransactionProcessor:
    """Processes blockchain transactions with full validation"""
    
    def __init__(self):
        self.pending_transactions = deque(maxlen=10000)
        self.transaction_history = deque(maxlen=100000)
        self.lock = threading.RLock()
        self.tx_count = 0
        self.block_threshold = 100
    
    def prepare_pseudoqubit_state(self, user_id: str, user_data: Dict):
        return {
            'user_id': user_id,
            'user_email': user_data.get('email'),
            'timestamp': datetime.now(timezone.utc).isoformat(),
            'state_vector': f"|{secrets.token_hex(8)}>",
            'coherence': 0.95,
            'entropy': 0.87,
            'measurement_basis': 'ghz3'
        }
    
    def prepare_ghz3_measurement(self, user_state: Dict, target_state: Dict, oracle_state: Dict):
        return {
            'measurement_type': 'ghz3_entanglement',
            'user_qubit': user_state,
            'target_qubit': target_state,
            'oracle_qubit': oracle_state,
            'timestamp': datetime.now(timezone.utc).isoformat(),
            'entanglement_strength': 0.87,
            'fidelity': 0.99,
            'phase': 45.0
        }
    
    def validate_user_balance(self, user_id: str, amount: Decimal):
        try:
            user_balance = Decimal('1000')
            if user_balance < amount:
                return False, f"Insufficient balance. Have {user_balance}, need {amount}", user_balance
            return True, f"Balance verified: {user_balance}", user_balance
        except Exception as e:
            return False, f"Error: {str(e)}", None
    
    def create_transaction(self, tx_data: Dict):
        try:
            tx_id = f"tx_{secrets.token_hex(16)}"
            transaction = {
                'tx_id': tx_id,
                'from_user': tx_data.get('from_user'),
                'to_user': tx_data.get('to_user'),
                'amount': Decimal(str(tx_data.get('amount', 0))),
                'timestamp': datetime.now(timezone.utc).isoformat(),
                'status': 'pending',
                'fee': Decimal('0.001')
            }
            with self.lock:
                self.pending_transactions.append(transaction)
                self.tx_count += 1
            logger.info(f"[TxProcessor] âœ“ Transaction created: {tx_id}")
            return True, f"Transaction {tx_id} created", tx_id
        except Exception as e:
            logger.error(f"[TxProcessor] Error: {e}")
            return False, f"Error: {str(e)}", None
    
    def execute_transaction(self, tx_id: str, password_hash: str):
        try:
            with self.lock:
                for tx in self.pending_transactions:
                    if tx['tx_id'] == tx_id:
                        tx['status'] = 'confirmed'
                        tx['confirmed_at'] = datetime.now(timezone.utc).isoformat()
                        receipt = {
                            'tx_id': tx_id,
                            'status': 'confirmed',
                            'amount': str(tx['amount']),
                            'fee': str(tx['fee'])
                        }
                        self.transaction_history.append(tx)
                        self.pending_transactions.remove(tx)
                        if self.tx_count >= self.block_threshold:
                            self._generate_new_block()
                        return True, "Transaction executed successfully", receipt
                return False, "Transaction not found", None
        except Exception as e:
            logger.error(f"[TxProcessor] Error: {e}")
            return False, f"Error: {str(e)}", None
    
    def _generate_new_block(self):
        try:
            block_id = f"block_{secrets.token_hex(16)}"
            block = {
                'block_id': block_id,
                'timestamp': datetime.now(timezone.utc).isoformat(),
                'transaction_count': self.tx_count,
                'miner': 'quantum_consensus'
            }
            logger.info(f"[BlockGen] âœ“ New block generated: {block_id}")
            self.tx_count = 0
            return block
        except Exception as e:
            logger.error(f"[BlockGen] Error: {e}")
            return None

_tx_processor = TransactionProcessor()

def get_tx_processor() -> TransactionProcessor:
    return _tx_processor

def get_user_balance(user_id: str) -> Decimal:
    return Decimal('1000')



# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# LEVEL 2 SUBLOGIC - COMPLETE SYSTEM INTEGRATION HUB
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class UnifiedSystemOrchestrator:
    """Master orchestrator coordinating all systems through GLOBALS"""
    
    _instance = None
    _lock = threading.RLock()
    
    def __new__(cls):
        if cls._instance is None:
            with cls._lock:
                if cls._instance is None:
                    cls._instance = super().__new__(cls)
        return cls._instance
    
    def __init__(self):
        self.global_state = None
        self.system_modules = {}
        self.interconnections = {}
        self.execution_context = {}
        self.initialize()
    
    def initialize(self):
        """Initialize orchestrator with all systems"""
        self.global_state = get_globals()
        
        # Register all system modules
        self.system_modules = {
            'quantum': None,
            'blockchain': None,
            'defi': None,
            'oracle': None,
            'ledger': None,
            'auth': None,
            'database': None,
            'terminal': None,
            'admin': None,
        }
        
        self._build_interconnections()
    
    def _build_interconnections(self):
        """Build all system interconnections"""
        # Quantum â†’ Everything (provides entropy & randomness)
        self.interconnections['quantum_core'] = {
            'quantum': ['entropy_generation', 'rng_feed'],
            'to': ['blockchain', 'defi', 'oracle', 'auth', 'ledger']
        }
        
        # Blockchain â†” Ledger â†” Database
        self.interconnections['ledger_blockchain_db'] = {
            'blockchain': ['tx_broadcast', 'state_sync'],
            'ledger': ['tx_record', 'account_state'],
            'database': ['persistent_storage', 'query_interface'],
            'bidirectional': True
        }
        
        # DeFi â†” Blockchain â†” Oracle
        self.interconnections['defi_oracle_chain'] = {
            'defi': ['liquidity_pool', 'trade_execution'],
            'blockchain': ['settlement', 'verification'],
            'oracle': ['price_feed', 'market_data'],
            'bidirectional': True
        }
        
        # Auth â†’ All systems (verification & authorization)
        self.interconnections['auth_verification'] = {
            'auth': ['user_verification', 'permission_check'],
            'to': ['blockchain', 'defi', 'oracle', 'ledger', 'terminal', 'admin'],
            'directional': True
        }
        
        # Terminal â†’ All systems (command execution)
        self.interconnections['terminal_commands'] = {
            'terminal': ['execute_command', 'state_query'],
            'to': ['quantum', 'blockchain', 'defi', 'oracle', 'ledger', 'admin'],
            'directional': True
        }
    
    def execute_command_across_systems(self, command, params):
        """Execute command with full system integration"""
        execution_id = str(uuid.uuid4())
        
        # Route command to appropriate system
        system = params.get('system')
        action = params.get('action')
        
        if system == 'quantum':
            return self._execute_quantum_command(action, params)
        elif system == 'blockchain':
            return self._execute_blockchain_command(action, params)
        elif system == 'defi':
            return self._execute_defi_command(action, params)
        elif system == 'oracle':
            return self._execute_oracle_command(action, params)
        elif system == 'ledger':
            return self._execute_ledger_command(action, params)
        
        return {'error': 'Unknown system'}
    
    def _execute_quantum_command(self, action, params):
        """Execute quantum system command"""
        # Quantum provides entropy/RNG to other systems
        result = {'system': 'quantum', 'action': action, 'status': 'executed'}
        
        # Notify blockchain if RNG needed
        if action == 'generate_rng':
            result['feeds_blockchain'] = True
            result['feeds_auth'] = True
        
        return result
    
    def _execute_blockchain_command(self, action, params):
        """Execute blockchain command"""
        result = {'system': 'blockchain', 'action': action, 'status': 'executed'}
        
        # Blockchain updates ledger
        result['updates_ledger'] = True
        result['writes_database'] = True
        
        # Blockchain consults oracle for prices
        if 'price_check' in str(params):
            result['queries_oracle'] = True
        
        return result
    
    def _execute_defi_command(self, action, params):
        """Execute DeFi command"""
        result = {'system': 'defi', 'action': action, 'status': 'executed'}
        
        # DeFi needs blockchain for settlement
        result['uses_blockchain'] = True
        
        # DeFi needs oracle for prices
        result['queries_oracle'] = True
        
        # DeFi needs auth for verification
        result['verifies_user'] = True
        
        return result
    
    def _execute_oracle_command(self, action, params):
        """Execute oracle command"""
        result = {'system': 'oracle', 'action': action, 'status': 'executed'}
        
        # Oracle data feeds blockchain and DeFi
        result['feeds_blockchain'] = True
        result['feeds_defi'] = True
        
        return result
    
    def _execute_ledger_command(self, action, params):
        """Execute ledger command"""
        result = {'system': 'ledger', 'action': action, 'status': 'executed'}
        
        # Ledger persists to database
        result['writes_database'] = True
        result['reads_blockchain'] = True
        
        return result
    
    def get_system_interconnection_graph(self):
        """Get complete system interconnection graph"""
        return {
            'orchestrator': 'active',
            'connections': self.interconnections,
            'modules': list(self.system_modules.keys()),
            'global_state': self.global_state is not None
        }

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# LEVEL 3 SUBLOGIC - DATA FLOW & STATE SYNCHRONIZATION
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class SystemDataFlowController:
    """Control data flow between all systems"""
    
    def __init__(self, orchestrator):
        self.orchestrator = orchestrator
        self.data_channels = {}
        self.state_sync_queue = queue.Queue(maxsize=10000)
        self.initialize_channels()
    
    def initialize_channels(self):
        """Initialize data flow channels"""
        # Quantum entropy channel
        self.data_channels['quantum_entropy'] = {
            'source': 'quantum',
            'consumers': ['blockchain', 'auth', 'defi'],
            'priority': 'high'
        }
        
        # Blockchain transaction channel
        self.data_channels['blockchain_tx'] = {
            'source': 'blockchain',
            'consumers': ['ledger', 'defi', 'oracle'],
            'priority': 'critical'
        }
        
        # Price feed channel
        self.data_channels['oracle_prices'] = {
            'source': 'oracle',
            'consumers': ['defi', 'blockchain', 'ledger'],
            'priority': 'high'
        }
        
        # Ledger state channel
        self.data_channels['ledger_state'] = {
            'source': 'ledger',
            'consumers': ['blockchain', 'defi'],
            'priority': 'medium'
        }
    
    def publish_data(self, channel, data):
        """Publish data to channel"""
        if channel in self.data_channels:
            self.state_sync_queue.put({
                'channel': channel,
                'data': data,
                'timestamp': datetime.now(timezone.utc).isoformat()
            })
            return True
        return False
    
    def sync_all_states(self):
        """Synchronize all system states"""
        # Pull from state sync queue
        synced_count = 0
        while not self.state_sync_queue.empty():
            try:
                msg = self.state_sync_queue.get_nowait()
                # Process state update
                synced_count += 1
            except queue.Empty:
                break
        return synced_count

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# GLOBAL ORCHESTRATOR INSTANCE
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

SYSTEM_ORCHESTRATOR = None
DATA_FLOW_CONTROLLER = None

def initialize_system_orchestration():
    """Initialize complete system orchestration"""
    global SYSTEM_ORCHESTRATOR, DATA_FLOW_CONTROLLER
    
    SYSTEM_ORCHESTRATOR = UnifiedSystemOrchestrator()
    DATA_FLOW_CONTROLLER = SystemDataFlowController(SYSTEM_ORCHESTRATOR)
    
    return SYSTEM_ORCHESTRATOR

def get_orchestrator():
    """Get system orchestrator instance"""
    if SYSTEM_ORCHESTRATOR is None:
        initialize_system_orchestration()
    return SYSTEM_ORCHESTRATOR


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# MASTER COMMAND REGISTRY â€” single dict populated at boot by terminal_logic.register_all_commands()
#
# Structure: { 'command-name': { 'handler': callable, 'category': str,
#                                'description': str, 'requires_auth': bool,
#                                'requires_admin': bool } }
#
# This dict IS the master registry list. wsgi_config reads it for dispatch + /api/commands.
# terminal_logic populates it. globals owns it.
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

COMMAND_REGISTRY: Dict[str, Dict] = {}


def get_command_registry() -> Dict[str, Dict]:
    """Get the master command registry."""
    return COMMAND_REGISTRY


def dispatch_command(raw: str, is_admin: bool = False, is_authenticated: bool = False) -> Dict[str, Any]:
    """
    Dispatch a raw command string through COMMAND_REGISTRY.
    Handles hyphen commands + flag parsing at globals level.

    Args:
        raw:              e.g. 'admin-users --limit=10' or 'help-admin'
        is_admin:         caller has admin privileges
        is_authenticated: caller is logged in

    Returns: dict with 'status', 'result' or 'error'
    
    ğŸ”´ CRITICAL FIX (2025-02-19):
    If COMMAND_REGISTRY is empty (size 0), this indicates terminal_logic
    failed to boot properly. Check wsgi_config logs for _boot_terminal()
    errors. Common causes:
    1. Missing dependencies (bcrypt, PyJWT, psycopg2)
    2. globals not fully initialized
    3. ensure_packages() pip install failure in externally-managed Python environment
    """
    import re

    # ğŸ”´ DIAGNOSTIC: Empty registry detection
    if len(COMMAND_REGISTRY) == 0:
        return {
            'status': 'error',
            'error': 'COMMAND_REGISTRY is empty â€” terminal_logic failed to boot',
            'debug_info': {
                'registry_size': 0,
                'possible_causes': [
                    'terminal_logic.py import failed (check logs)',
                    'Missing dependencies: bcrypt, PyJWT, psycopg2',
                    'globals not fully initialized',
                    'TerminalEngine instantiation failed'
                ],
                'action': 'Check wsgi_config.log for _boot_terminal() error details'
            }
        }

    if not raw or not raw.strip():
        return {'status': 'error', 'error': 'Empty command'}

    tokens = raw.strip().split()
    # Normalise: frontend sends category/command (slash) OR category-command (hyphen).
    # Backend registry is 100% hyphen-keyed. Replace every / with - so both work.
    name   = tokens[0].lower().replace('/', '-')
    args   = []
    flags  = {}

    # â”€â”€ Smart help- prefix expansion â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # 'help-admin'         â†’ {'category': 'admin'}  routed to 'help-category'
    # 'help-admin-users'   â†’ {'command': 'admin-users'}  routed to 'help-command'
    if name.startswith('help-') and name not in COMMAND_REGISTRY:
        suffix = name[5:]  # strip 'help-'
        if suffix in {e['category'] for e in COMMAND_REGISTRY.values()}:
            name = 'help-category'
            flags = {'category': suffix}
        else:
            # Assume it's a command name
            name  = 'help-command'
            flags = {'command': suffix}
    else:
        for tok in tokens[1:]:
            m = re.match(r'^--([a-zA-Z0-9_-]+)(?:=(.+))?$', tok)
            if m:
                key = m.group(1).replace('-', '_')
                flags[key] = m.group(2) if m.group(2) is not None else True
            else:
                args.append(tok)

    # â”€â”€ Inline --help flag â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    if flags.get('help'):
        entry = COMMAND_REGISTRY.get(name, {})
        return {
            'status': 'success',
            'result': {
                'output': (
                    f'  COMMAND: {name}\n'
                    f'  Category: {entry.get("category","?")}\n'
                    f'  Auth: {"ADMIN" if entry.get("requires_admin") else "AUTH" if entry.get("requires_auth") else "none"}\n'
                    f'  Description: {entry.get("description","?")}'
                )
            }
        }

    entry = COMMAND_REGISTRY.get(name)
    if not entry:
        # Fuzzy suggestion
        candidates = [n for n in COMMAND_REGISTRY if n.startswith(name[:min(4, len(name))])]
        return {
            'status':      'error',
            'error':       f"Command '{name}' not found. Try 'help-commands'.",
            'suggestions': candidates[:5],
        }

    # â”€â”€ Auth check â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    if entry.get('requires_admin') and not is_admin:
        return {'status': 'error', 'error': f"'{name}' requires admin privileges"}
    if entry.get('requires_auth') and not is_authenticated and not is_admin:
        return {'status': 'error', 'error': f"'{name}' requires authentication. Run: login --email=x --password=y"}

    try:
        result = entry['handler'](flags, args)
        # Track metrics
        try:
            get_globals().metrics.commands_executed += 1
        except Exception:
            pass
        return result
    except Exception as exc:
        logger.error(f'[dispatch_command] {name} raised: {exc}', exc_info=True)
        return {'status': 'error', 'error': str(exc)}
